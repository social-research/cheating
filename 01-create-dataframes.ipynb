{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Create a table for each data in parquet format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We use **six datasets** for different purposes in this project.\n",
    "\n",
    "1. Dataset that contains player (node) data\n",
    "* Dataset that contains raw telemetry data for general statistics\n",
    "* Dataset for cheater analysis\n",
    "* Dataset that contains the team IDs of players who took part in teamplay matches \n",
    "* Dataset for estimating the start date of cheating and analysing the victimisation-based mechanism\n",
    "* Dataset for analysing the observation-based mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, TimestampType\n",
    "import pubg_analysis as pubg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a dataset that contains player data.\n",
    "\n",
    "The table below describes the variables in the player data:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| id         | ID of the player               \n",
    "| pname      | nickname of the player  \n",
    "| cheating_flag     | 1 if the player was banned, 0 otherwise\n",
    "| ban_date   | date in the format YYYY-MM-DD when the cheater was banned \n",
    "\n",
    "As shown below, there are 1,977,329 unique players and 6,161 players among them are cheaters in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------------+--------+\n",
      "|                  id|          pname|cheating_flag|ban_date|\n",
      "+--------------------+---------------+-------------+--------+\n",
      "|account.1d0281ff2...|      ulimnet10|            0|      NA|\n",
      "|account.1c295c6c0...|       yoon9242|            0|      NA|\n",
      "|account.a2b8791d5...|        meco001|            0|      NA|\n",
      "|account.e3b1eb159...|         forsir|            0|      NA|\n",
      "|account.65433d8ee...|      jimin0311|            0|      NA|\n",
      "|account.74c0462cd...|namyoonwoo07074|            0|      NA|\n",
      "|account.64d031587...|       wreu1234|            0|      NA|\n",
      "|account.7f874085e...|        kbs4799|            0|      NA|\n",
      "|account.5c8366a6b...|       ssabu110|            0|      NA|\n",
      "|account.d89f4429c...|      gusrb0187|            0|      NA|\n",
      "+--------------------+---------------+-------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the structure of player data.\n",
    "nodeSchema = StructType([StructField(\"id\", StringType(), True),\n",
    "                         StructField(\"pname\", StringType(), True),\n",
    "                         StructField(\"cheating_flag\", IntegerType(), True),\n",
    "                         StructField(\"ban_date\", StringType(), True)])\n",
    "\n",
    "# Create a table of player data and store it in the S3 bucket.\n",
    "PATH_TO_FILE = \"s3://social-research-cheating/td_nodes.txt\"\n",
    "\n",
    "players = spark.read.options(header='false', delimiter='\\t').schema(nodeSchema).csv(PATH_TO_FILE)\n",
    "players.write.parquet(\"s3://social-research-cheating/players.parquet\")\n",
    "players.registerTempTable(\"players\")\n",
    "\n",
    "# Show the top 10 rows of the dataset.\n",
    "players.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977329\n",
      "+------------------+\n",
      "|count(DISTINCT id)|\n",
      "+------------------+\n",
      "|           1977329|\n",
      "+------------------+\n",
      "\n",
      "+------------------+\n",
      "|count(DISTINCT id)|\n",
      "+------------------+\n",
      "|              6161|\n",
      "+------------------+\n",
      "\n",
      "6161\n"
     ]
    }
   ],
   "source": [
    "# Count the number of players and check whether there are any duplicates.\n",
    "print(players.count())\n",
    "\n",
    "test_players = spark.sql(\"SELECT COUNT(DISTINCT id) FROM players\")\n",
    "test_players.show()\n",
    "\n",
    "# Count the number of cheaters and check whether there are any duplicates.\n",
    "test_players = spark.sql(\"\"\"SELECT COUNT(DISTINCT id) FROM players \n",
    "                            WHERE cheating_flag = 1\"\"\")\n",
    "test_players.show()\n",
    "\n",
    "cheaters = spark.sql(\"SELECT * FROM players WHERE cheating_flag = 1\")\n",
    "cheaters.registerTempTable(\"cheaters\")\n",
    "print(cheaters.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|  ban_date|num_of_cheaters|\n",
      "+----------+---------------+\n",
      "|2019-03-03|            258|\n",
      "|2019-03-11|            511|\n",
      "|2019-03-28|             99|\n",
      "|2019-03-07|            262|\n",
      "|2019-03-20|            112|\n",
      "|2019-03-19|            116|\n",
      "|2019-03-01|            103|\n",
      "|2019-03-23|            176|\n",
      "|2019-03-30|             93|\n",
      "|2019-03-16|            107|\n",
      "|2019-03-05|            228|\n",
      "|2019-03-29|            114|\n",
      "|2019-03-25|             89|\n",
      "|2019-03-31|             89|\n",
      "|2019-03-14|            139|\n",
      "|2019-03-15|            132|\n",
      "|2019-03-10|            135|\n",
      "|2019-03-17|            144|\n",
      "|2019-03-22|            118|\n",
      "|2019-03-26|            170|\n",
      "+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of cheaters by ban date.\n",
    "num_of_cheaters = spark.sql(\"\"\"SELECT ban_date, COUNT(*) AS num_of_cheaters \n",
    "                               FROM cheaters GROUP BY ban_date\"\"\")\n",
    "num_of_cheaters.show()\n",
    "\n",
    "# Store the table in the S3 bucket for the later use (plotting general statistics).\n",
    "num_of_cheaters.write.parquet(\"s3://social-research-cheating/general-stats/num_of_cheaters.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a raw dataset that contains killings. \n",
    "\n",
    "This dataset will be used for general statistics.\n",
    "\n",
    "The table below describes the variables in the telemetry data:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid         | ID of the match               \n",
    "| src      | ID of the killer  \n",
    "| dst     | ID of the victim \n",
    "| time   | time in the format YYYY-MM-DD HH:MM:SS.SSS Z when the attack (killing) happened\n",
    "| m_date   | date in the format YYYY-MM-DD when the match was played \n",
    "\n",
    "There are 1,146,941 unique matches played during the observation period.<br>\n",
    "The total number of killings (edges) including self-loops in the dataset is 98,319,451."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_nums = [(1, 7), (2, 7), (3, 7), (4, 4), (5, 4), \n",
    "             (6, 4), (7, 4), (8, 5), (9, 7), (10, 6),\n",
    "             (11, 4), (12, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_RAW_DATA = \"s3://social-research-cheating/edges/raw_td.parquet\"\n",
    "\n",
    "for tup in file_nums:\n",
    "    pubg.combine_telemetry_data(tup[0], tup[1], PATH_TO_RAW_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98319451\n"
     ]
    }
   ],
   "source": [
    "# Read telemetry data stored in my S3 bucket.\n",
    "raw_td = spark.read.parquet(\"s3://social-research-cheating/raw_td.parquet\")\n",
    "raw_td.registerTempTable(\"raw_td\")\n",
    "\n",
    "# Count the number of rows (= killings) in the dataframe.\n",
    "print(raw_td.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                 mid|                 src|                 dst|                time|    m_date|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|01fd8f35-01ff-48f...|account.f1ef62d78...|account.bf5a2bdf5...|2019-03-03 14:19:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.e80a530e6...|account.8bd3cc440...|2019-03-03 14:19:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.e80a530e6...|account.52accebe5...|2019-03-03 14:19:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.6961c79f1...|account.e28657d14...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.caa44db60...|account.749a9649f...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.749a9649f...|account.6b9c75259...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.749a9649f...|account.02fe9c7cb...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.d7d801641...|account.caa44db60...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.6961c79f1...|account.a978bced1...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.6961c79f1...|account.f1ef62d78...|2019-03-03 14:20:...|2019-03-03|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the top 10 rows of the dataset.\n",
    "raw_td.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT mid)|\n",
      "+-------------------+\n",
      "|            1146941|\n",
      "+-------------------+\n",
      "\n",
      "+----------+-----------+\n",
      "|    m_date|num_of_mids|\n",
      "+----------+-----------+\n",
      "|2019-03-03|      45696|\n",
      "|2019-03-11|      29363|\n",
      "|2019-03-28|      24271|\n",
      "|2019-03-07|      31267|\n",
      "|2019-03-20|      29240|\n",
      "|2019-03-19|      29523|\n",
      "|2019-03-01|      48886|\n",
      "|2019-03-23|      50375|\n",
      "|2019-03-30|      49550|\n",
      "|2019-03-16|      50550|\n",
      "|2019-03-05|      30504|\n",
      "|2019-03-29|      36189|\n",
      "|2019-03-25|      29115|\n",
      "|2019-03-31|      45487|\n",
      "|2019-03-14|      29890|\n",
      "|2019-03-15|      37090|\n",
      "|2019-03-10|      46290|\n",
      "|2019-03-17|      45816|\n",
      "|2019-03-22|      36154|\n",
      "|2019-03-26|      27491|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique match IDs.\n",
    "unique_mids = spark.sql(\"SELECT COUNT(DISTINCT mid) FROM raw_td\")\n",
    "unique_mids.show()\n",
    "\n",
    "# Count the number of matches by date.\n",
    "mids_by_date = spark.sql(\"\"\"SELECT m_date, COUNT(DISTINCT mid) AS num_of_mids \n",
    "                            FROM raw_td GROUP BY m_date\"\"\")\n",
    "mids_by_date.show()\n",
    "\n",
    "# Store the table in the S3 bucket for the later use (plotting general statistics).\n",
    "mids_by_date.write.parquet(\"s3://social-research-cheating/general-stats/mids_by_date.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a dataset for cheater analysis.\n",
    "\n",
    "To compare cheaters and non-cheaters, we need to extract the records of matches played between March 1 and March 3.<br>\n",
    "The number of killings without self-loops between March 1 and March 3 is 12,216,898.\n",
    "\n",
    "The table below describes the variables in the data for cheater analysis:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid         | ID of the match               \n",
    "| src      | ID of the killer  \n",
    "| dst     | ID of the victim \n",
    "| time   | time in the format YYYY-MM-DD HH:MM:SS.SSS Z when the attack (killing) happened\n",
    "| m_date   | date in the format YYYY-MM-DD when the match was played "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12216898\n"
     ]
    }
   ],
   "source": [
    "raw_td = spark.read.parquet(\"s3://social-research-cheating/raw_td.parquet\")\n",
    "raw_td.registerTempTable(\"raw_td\")\n",
    "\n",
    "# Create a small dataset without self-loops.\n",
    "# The dataset below does not contain invalid edges (= edges with NULL).\n",
    "td = spark.sql(\"SELECT * FROM raw_td WHERE m_date <= '2019-03-03' AND src != dst\")\n",
    "print(td.count())\n",
    "\n",
    "# Store the data in the S3 bucket.\n",
    "td.write.parquet(\"s3://social-research-cheating/cheater-analysis/data_for_cheater_analysis.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a dataset that contains team membership information.\n",
    "\n",
    "The table below describes the variables in the team membership data:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid        | ID of the match               \n",
    "| id     | ID of the player  \n",
    "| tid     | ID of the team\n",
    "\n",
    "The number of teamplay matches is 1,022,520."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tables that contain the team membership information into one table.\n",
    "PATH_TO_TEAM_DATA = \"s3://social-research-cheating/team_data.parquet\"\n",
    "\n",
    "pubg.combine_team_data(31, 6, PATH_TO_TEAM_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+\n",
      "|                 mid|                  id|tid|\n",
      "+--------------------+--------------------+---+\n",
      "|b6a091d4-2bdb-451...|account.9fbe4bbe5...|  1|\n",
      "|24d0a877-2d20-43a...|account.9ad264163...| 17|\n",
      "|866b5d75-0d8f-497...|account.4c10d9e9f...| 47|\n",
      "|476c22d8-d929-46c...|account.74c896572...| 21|\n",
      "|499aa106-272e-468...|account.bebee03c5...| 29|\n",
      "|355aafa1-b7a2-45c...|account.289b29eda...| 13|\n",
      "|4020041c-a4a6-46f...|account.4d93bc13f...| 35|\n",
      "|450b9c1c-6bd0-4d7...|account.a8a2ff4b7...| 15|\n",
      "|79ca6d6c-8f3a-485...|account.452fb2497...| 30|\n",
      "|02c36bd8-de13-479...|account.1a3ac664c...| 14|\n",
      "+--------------------+--------------------+---+\n",
      "only showing top 10 rows\n",
      "\n",
      "93730706\n"
     ]
    }
   ],
   "source": [
    "# Read the data stored in the S3 bucket.\n",
    "PATH_TO_TEAM_DATA = \"s3://social-research-cheating/team_data.parquet\"\n",
    "team_data = spark.read.parquet(PATH_TO_TEAM_DATA)\n",
    "\n",
    "# Show the top 10 rows of the dataset.\n",
    "team_data.show(10)\n",
    "\n",
    "# Count the number of rows in the dataframe.\n",
    "print(team_data.count())\n",
    "# The number of rows is 93,730,706."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data stored in the S3 bucket. \n",
    "team_data = spark.read.parquet(\"s3://social-research-cheating/team_data.parquet\")\n",
    "team_data.registerTempTable(\"team_data\")\n",
    "\n",
    "raw_td = spark.read.parquet(\"s3://social-research-cheating/raw_td.parquet\")\n",
    "raw_td.registerTempTable(\"raw_td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique match IDs in the raw data.\n",
    "unique_mids = spark.sql(\"SELECT DISTINCT mid FROM raw_td\")\n",
    "unique_mids.registerTempTable(\"unique_mids\")\n",
    "unique_mids.write.parquet(\"s3://social-research-cheating/general-stats/unique_mids.parquet\")\n",
    "\n",
    "# Get unique match IDs in the team membership data.\n",
    "unique_team_mids = spark.sql(\"SELECT DISTINCT mid FROM team_data\")\n",
    "unique_team_mids.registerTempTable(\"unique_team_mids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of match IDs in both tables.\n",
    "team_mids = spark.sql(\"SELECT t.mid FROM unique_team_mids t JOIN unique_mids m ON t.mid = m.mid\")\n",
    "team_mids.write.parquet(\"s3://social-research-cheating/general-stats/unique_team_mids.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT mid)|\n",
      "+-------------------+\n",
      "|            1022520|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "team_mids = spark.read.parquet(\"s3://social-research-cheating/general-stats/unique_team_mids.parquet\")\n",
    "team_mids.registerTempTable(\"team_mids\")\n",
    "\n",
    "# Count the number of unique match IDs in the team membership data.\n",
    "team_mid_cnt = spark.sql(\"SELECT COUNT(DISTINCT mid) FROM team_mids\")\n",
    "team_mid_cnt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small team dataset.\n",
    "team_data = spark.read.parquet(\"s3://social-research-cheating/edges/small_team_data.parquet\")\n",
    "team_data.registerTempTable(\"team_data\")\n",
    "\n",
    "obs_data = spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\")\n",
    "obs_data.registerTempTable(\"obs_data\")\n",
    "\n",
    "# Get a list of unique match IDs from 'obs_data'.\n",
    "obs_mids = spark.sql(\"SELECT DISTINCT mid FROM obs_data\")\n",
    "obs_mids.registerTempTable(\"obs_mids\")\n",
    "\n",
    "# Count the number of match IDs in both tables.\n",
    "team_mids = spark.sql(\"SELECT t.mid, id, tid FROM team_data t JOIN obs_mids o ON t.mid = o.mid\")\n",
    "team_mids.write.parquet(\"s3://social-research-cheating/edges/tiny_team_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a dataset for the use of analysing the observation-based mechanism.\n",
    "\n",
    "The dataset for analysing the observation-based mechanism should contain self-loops because players who killed themselves (self-loops) cannot observe what happens in the match after they die.<br>\n",
    "To reduce the amount of data, we extract the matches where at least one player was killed by cheating.<br>\n",
    "The number of unique match IDs in this dataset is 19,216.<br>\n",
    "\n",
    "The table below describes the variables in the data for analysing the observation-based mechanism:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid         | ID of the match               \n",
    "| src      | ID of the killer\n",
    "| src_sd      | date in the format YYYY-MM-DD when the killer started cheating ('NA' if the player is a non-cheater)\n",
    "| src_bd      | date in the format YYYY-MM-DD when the killer was banned ('NA' if the player is a non-cheater)\n",
    "| src_curr_flag      | 1 if the killer was cheating on the date when the match was played\n",
    "| src_flag      | 1 if the killer was banned, 0 otherwise\n",
    "| dst     | ID of the victim\n",
    "| dst_sd      | date in the format YYYY-MM-DD when the victim started cheating ('NA' if the player is a non-cheater)\n",
    "| dst_bd      | date in the format YYYY-MM-DD when the victim was banned ('NA' if the player is a non-cheater)\n",
    "| dst_curr_flag      | 1 if the victim was cheating on the date when the match was played\n",
    "| dst_flag      | 1 if the victim was banned, 0 otherwise\n",
    "| time   | time in the format YYYY-MM-DD HH:MM:SS.SSS Z when the attack (killing) happened\n",
    "| m_date   | date in the format YYYY-MM-DD when the match was played\n",
    "\n",
    "The number of edges is 1,693,699 and there are 7,522 self-loops in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_RAW_DATA = \"s3://social-research-cheating/raw_td.parquet\"\n",
    "players = spark.read.parquet(\"s3://social-research-cheating/nodes.parquet\")\n",
    "players.registerTempTable(\"players\")\n",
    "\n",
    "# Get the logs of the matches where at least one cheater took part in.\n",
    "pubg.get_obs_data(PATH_TO_RAW_DATA, players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1693699\n",
      "7522\n"
     ]
    }
   ],
   "source": [
    "obs_data = spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\")\n",
    "obs_data.registerTempTable(\"obs_data\")\n",
    "\n",
    "# Count the number of rows in the dataframe.\n",
    "print(obs_data.count())\n",
    "\n",
    "# Count the number of self-loops.\n",
    "self_loops = spark.sql(\"SELECT * FROM obs_data WHERE src = dst\")\n",
    "print(self_loops.count())\n",
    "\n",
    "# The number of edges is 1,693,699 and there are 7,522 self-loops in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a dataset for the use of analysing the victimisation-based mechanism.\n",
    "\n",
    "We need the killing records of matches where cheaters killed at least one player without self-loops.<br> \n",
    "We can simply reuse the dataset for the observation-based mechanism by getting rid of self-loops from it.<br>\n",
    "Thus, the number of edges should be 1,693,699 - 7,522 = 1,686,177.\n",
    "\n",
    "The table below describes the variables in the data for analysing the victimisation-based mechanism:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid         | ID of the match               \n",
    "| src      | ID of the killer\n",
    "| src_sd      | date in the format YYYY-MM-DD when the killer started cheating ('NA' if the player is a non-cheater)\n",
    "| src_bd      | date in the format YYYY-MM-DD when the killer was banned ('NA' if the player is a non-cheater)\n",
    "| src_curr_flag      | 1 if the killer was cheating on the date when the match was played\n",
    "| src_flag      | 1 if the killer was banned, 0 otherwise\n",
    "| dst     | ID of the victim\n",
    "| dst_sd      | date in the format YYYY-MM-DD when the victim started cheating ('NA' if the player is a non-cheater)\n",
    "| dst_bd      | date in the format YYYY-MM-DD when the victim was banned ('NA' if the player is a non-cheater)\n",
    "| dst_flag      | 1 if the victim was banned, 0 otherwise\n",
    "| dst_curr_flag      | 1 if the victim was cheating on the date when the match was played\n",
    "| time   | time in the format YYYY-MM-DD HH:MM:SS.SSS Z when the attack (killing) happened\n",
    "| m_date   | date in the format YYYY-MM-DD when the match was played\n",
    "\n",
    "The number of edges in this dataset is 1,686,177."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for analysing the victimisation-based mechanism.\n",
    "spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\").createOrReplaceTempView(\"raw_data\")\n",
    "cleaned_data = spark.sql(\"SELECT * FROM raw_data WHERE src != dst\") # Remove self-loops.\n",
    "cleaned_data.write.parquet(\"s3://social-research-cheating/edges/vic_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1686177\n"
     ]
    }
   ],
   "source": [
    "vic_data = spark.read.parquet(\"s3://social-research-cheating/edges/vic_data.parquet\")\n",
    "print(vic_data.count())\n",
    "\n",
    "# The number of edges should be 1,693,699 - 7,522 = 1,686,177."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Check the number of winners and test whether winners have the same team ID for each match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a table that contains killings.\n",
    "obs_data = spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\")\n",
    "obs_data.registerTempTable(\"obs_data\")\n",
    "\n",
    "# Read a table that contains team membership data.\n",
    "team_info = spark.read.parquet(\"s3://social-research-cheating/edges/tiny_team_data.parquet\")\n",
    "team_info.registerTempTable(\"team_ids\")\n",
    "\n",
    "players = spark.read.parquet(\"s3://social-research-cheating/nodes.parquet\")\n",
    "players.registerTempTable(\"players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+-------+-------+\n",
      "|                 mid|winner_cnt|tid_cnt|pot_cnt|na_flag|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "|0143e2da-14d2-4d8...|         9|      6|      0|      0|\n",
      "|036a8903-186b-45f...|         4|      2|      0|      0|\n",
      "|080d5622-6b94-4d7...|         3|      2|      0|      0|\n",
      "|0c7d472e-5064-4d4...|         2|      2|      0|      0|\n",
      "|0ef25288-88d3-476...|         2|      1|      0|      0|\n",
      "|1203abce-50ec-40d...|         4|      4|      0|      0|\n",
      "|1574a6bb-a63f-473...|         5|      2|      0|      0|\n",
      "|16d6f605-4118-4de...|         4|      3|      0|      0|\n",
      "|1773f8d7-b807-439...|         3|      2|      0|      0|\n",
      "|194e1d81-b65c-4dc...|         4|      2|      0|      0|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a list of mids and m_dates.\n",
    "match_info = spark.sql(\"SELECT DISTINCT mid, m_date FROM obs_data\")\n",
    "match_info.registerTempTable(\"match_info\")\n",
    "\n",
    "# Get a list of victims for each match.\n",
    "victims = spark.sql(\"SELECT DISTINCT mid, dst FROM obs_data\")\n",
    "victims.registerTempTable(\"victims\")\n",
    "\n",
    "# Get a list of winners for each match.\n",
    "winners = spark.sql(\"\"\"SELECT DISTINCT o.mid, src FROM obs_data o \n",
    "                       WHERE NOT EXISTS (SELECT mid, dst FROM victims v WHERE o.mid = v.mid AND o.src = v.dst)\"\"\")\n",
    "winners.registerTempTable(\"winners\")\n",
    "\n",
    "# Add team information.\n",
    "add_tids = spark.sql(\"\"\"SELECT w.mid, src, CASE WHEN tid IS NULL THEN 'NA' ELSE tid END AS src_tid\n",
    "                        FROM winners w LEFT JOIN team_ids t ON w.mid = t.mid AND w.src = t.id\"\"\")\n",
    "add_tids.registerTempTable(\"add_tids\")\n",
    "\n",
    "# Add m_dates.\n",
    "temp_tab = spark.sql(\"\"\"SELECT a.mid, src, src_tid, m_date \n",
    "                        FROM add_tids a LEFT JOIN match_info m ON a.mid = m.mid\"\"\")\n",
    "temp_tab.registerTempTable(\"temp_tab\")\n",
    "\n",
    "# Find the matches where at least one winner's team ID is 'NA'.\n",
    "na_tids = spark.sql(\"SELECT DISTINCT mid FROM add_tids WHERE src_tid = 'NA'\")\n",
    "na_tids.registerTempTable(\"na_tids\")\n",
    "\n",
    "# Add the current cheating flag of players.\n",
    "winners = spark.sql(\"\"\"SELECT t.*, \n",
    "                       CASE WHEN cheating_flag = 1 AND m_date < start_date THEN 1 ELSE 0 END AS pot_flag \n",
    "                       FROM temp_tab t LEFT JOIN players p ON t.src = p.id\"\"\")\n",
    "winners.registerTempTable(\"winners\")\n",
    "\n",
    "# Count the number of winners and that of unique times for each match. \n",
    "cnt_tab = spark.sql(\"\"\"SELECT mid, COUNT(src) AS winner_cnt, \n",
    "                       COUNT(DISTINCT src_tid) AS tid_cnt, SUM(pot_flag) AS pot_cnt \n",
    "                       FROM winners GROUP BY mid\"\"\")\n",
    "cnt_tab.registerTempTable(\"cnt_tab\")\n",
    "\n",
    "summary_tab = spark.sql(\"\"\"SELECT c.mid, winner_cnt, tid_cnt, pot_cnt, \n",
    "                           CASE WHEN n.mid IS NULL THEN 0 ELSE 1 END AS na_flag \n",
    "                           FROM cnt_tab c LEFT JOIN na_tids n ON c.mid = n.mid\"\"\")\n",
    "summary_tab.registerTempTable(\"summary_tab\")\n",
    "summary_tab.show(10)\n",
    "\n",
    "# summary_tab.write.parquet(\"s3://social-research-cheating/general-stats/sum_tab_of_winners.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+-------+-------+\n",
      "|                 mid|winner_cnt|tid_cnt|pot_cnt|na_flag|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "|013caebc-8504-4d7...|         4|      4|      1|      0|\n",
      "|0bd6149a-c6f5-4ed...|         9|      7|      1|      0|\n",
      "|0c2c1334-9af0-41d...|        11|      6|      1|      0|\n",
      "|2dc03f99-5d44-42e...|         7|      5|      1|      0|\n",
      "|35866cf5-93de-48a...|         4|      2|      1|      0|\n",
      "|391b03c1-3393-4af...|         9|      5|      1|      0|\n",
      "|3bbd09e0-d4af-4ac...|         5|      3|      1|      0|\n",
      "|456bc019-80ee-4c6...|         4|      3|      1|      0|\n",
      "|86ef180f-da6b-4b2...|         5|      3|      1|      0|\n",
      "|9c7144ce-008e-41d...|         5|      3|      1|      0|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "1964\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary_tab = spark.read.parquet(\"s3://social-research-cheating/general-stats/sum_tab_of_winners.parquet\")\n",
    "summary_tab.registerTempTable(\"summary_tab\")\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM summary_tab WHERE tid_cnt > 1 AND pot_cnt >= 1\")\n",
    "temp.show(10)\n",
    "print(temp.count())\n",
    "\n",
    "# Store a list of match IDs with multiple winners.\n",
    "# temp_df = temp.toPandas()\n",
    "# temp_df.to_csv('mids_multiple_winners.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+-------+-------+\n",
      "|                 mid|winner_cnt|tid_cnt|pot_cnt|na_flag|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "|9d8edf15-f814-48f...|         5|      2|      1|      1|\n",
      "|b2c7e5a4-f0f0-48d...|         5|      3|      1|      1|\n",
      "|dfae8103-19b6-4c1...|         7|      6|      1|      1|\n",
      "|b62ae865-af8e-4e3...|         3|      2|      2|      1|\n",
      "|2da2cc0d-41d1-487...|         9|      5|      1|      1|\n",
      "|12bcdfe5-34a4-473...|         4|      3|      1|      1|\n",
      "|13c1ad12-8e12-4a1...|         9|      6|      1|      1|\n",
      "|bb78c330-ea48-42a...|         4|      2|      1|      1|\n",
      "|7b6c2381-afde-452...|        13|      9|      1|      1|\n",
      "|f2f76e66-9fb7-40d...|         8|      6|      1|      1|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "summary_tab = spark.read.parquet(\"s3://social-research-cheating/general-stats/sum_tab_of_winners.parquet\")\n",
    "summary_tab.registerTempTable(\"summary_tab\")\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM summary_tab WHERE tid_cnt > 1 AND pot_cnt >= 1 AND na_flag = 1\")\n",
    "temp.show(10)\n",
    "print(temp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19216\n"
     ]
    }
   ],
   "source": [
    "uniq_mids = spark.sql(\"SELECT DISTINCT mid FROM obs_data\")\n",
    "print(uniq_mids.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM summary_tab WHERE tid_cnt > 1 AND pot_cnt >= 1 AND na_flag = 1\")\n",
    "temp_df = temp.toPandas()\n",
    "temp_df.to_csv('na_flags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Create a dataset that contains the ranks of teams (for teamplay matches)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below describes the variables in the team rank data:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid        | ID of the match               \n",
    "| tid     | ID of the team\n",
    "| mod     | game mode of the match\n",
    "| rank     | rank of the team (integer)\n",
    "| m_date     | date in the format YYYY-MM-DD when the match was played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that contains the ranks of teams for each teamplay match.\n",
    "PATH_TO_DATA = \"s3://social-research-cheating/edges/team_ranks.parquet\"\n",
    "\n",
    "team_data = pubg.get_team_ranks(\"md_day_1_1\")\n",
    "team_data.write.parquet(PATH_TO_DATA)\n",
    "    \n",
    "for i in range(2, 7):\n",
    "    team_data = pubg.get_team_ranks(\"md_day_1_\" + str(i))\n",
    "    team_data.write.mode(\"append\").parquet(PATH_TO_DATA)\n",
    "    \n",
    "file_nums = [(2, 6), (3, 6), (4, 5), (5, 5), \n",
    "             (6, 5), (7, 5), (8, 5), (9, 7), (10, 6),\n",
    "             (11, 4), (12, 5), (13, 5), (14, 5), (15, 5), \n",
    "             (16, 6), (17, 6), (18, 4), (19, 4), (20, 4), \n",
    "             (21, 5), (22, 5), (23, 7), (24, 7), (25, 4), \n",
    "             (26, 4), (27, 4), (28, 3), (29, 4), (30, 6), (31, 6)]\n",
    "\n",
    "for tup in file_nums:\n",
    "    for i in range(1, tup[1] + 1):\n",
    "        team_data = pubg.get_team_ranks(\"md_day_\" + str(tup[0]) + \"_\" + str(i))\n",
    "        team_data.write.mode(\"append\").parquet(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+-----+----+----------+\n",
      "|                 mid|tid|  mod|rank|    m_date|\n",
      "+--------------------+---+-----+----+----------+\n",
      "|f905942d-149d-49d...| 38|  duo|   3|2019-03-17|\n",
      "|a8f5eca6-cc65-480...| 15|squad|   7|2019-03-17|\n",
      "|2b708e1f-5496-4fb...| 24|  duo|  29|2019-03-17|\n",
      "|63514f97-098a-496...| 30|  duo|   9|2019-03-17|\n",
      "|3b171f42-13c5-4df...| 26|squad|   5|2019-03-17|\n",
      "+--------------------+---+-----+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank_data = spark.read.parquet(\"s3://social-research-cheating/edges/team_ranks.parquet\")\n",
    "rank_data.registerTempTable(\"rank_data\")\n",
    "rank_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1964\n"
     ]
    }
   ],
   "source": [
    "# Create a dataset that contains the ranks of teams for the teamplay matches\n",
    "# where winners have different team IDs and at least one potential cheater exists as a winner.\n",
    "# Run this cell only once.\n",
    "\n",
    "summary_tab = spark.read.parquet(\"s3://social-research-cheating/general-stats/sum_tab_of_winners.parquet\")\n",
    "summary_tab.registerTempTable(\"summary_tab\")\n",
    "\n",
    "invalid_mids = spark.sql(\"SELECT DISTINCT mid FROM summary_tab WHERE tid_cnt > 1 AND pot_cnt >= 1\")\n",
    "invalid_mids.registerTempTable(\"invalid_mids\")\n",
    "print(invalid_mids.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_ranks = spark.read.parquet(\"s3://social-research-cheating/edges/team_ranks.parquet\")\n",
    "team_ranks.registerTempTable(\"team_ranks\")\n",
    "\n",
    "sampled_ranks = spark.sql(\"\"\"SELECT t.* FROM team_ranks t JOIN invalid_mids i ON t.mid = i.mid \n",
    "                             ORDER BY mid, rank\"\"\")\n",
    "sampled_ranks.write.parquet(\"s3://social-research-cheating/edges/sampled_ranks.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_data = spark.read.parquet(\"s3://social-research-cheating/edges/sampled_ranks.parquet\")\n",
    "rank_data.registerTempTable(\"rank_data\")\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM rank_data WHERE mid = '9d8edf15-f814-48fc-95ec-a7dc6ff24f41'\")\n",
    "temp_df = temp.toPandas()\n",
    "temp_df.to_csv('rank_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Add additional self-loops in 'obs_data'.\n",
    "\n",
    "First, add self-loops for the cases where winners have different team IDs and no team has 'NA' as its team ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_ids = spark.read.parquet(\"s3://social-research-cheating/edges/tiny_team_data.parquet\")\n",
    "team_ids.registerTempTable(\"team_ids\")\n",
    "\n",
    "obs_data = spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\")\n",
    "obs_data.registerTempTable(\"obs_data\")\n",
    "\n",
    "# It contains the ranks of players for 1,964 teamplay matches. \n",
    "team_ranks = spark.read.parquet(\"s3://social-research-cheating/edges/ordered_ranks.parquet\")\n",
    "team_ranks.registerTempTable(\"team_ranks\")\n",
    "\n",
    "players = spark.read.parquet(\"s3://social-research-cheating/nodes.parquet\")\n",
    "players.registerTempTable(\"players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = spark.sql(\"SELECT * FROM obs_data WHERE mid = '013caebc-8504-4d71-be02-a082ddccda9a'\")\n",
    "temp_df = temp.toPandas()\n",
    "temp_df.to_csv('obs_data.csv')\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM team_ids WHERE mid = '0e85fbcc-0d91-4f03-942e-c92b5fae991f'\")\n",
    "temp_df = temp.toPandas()\n",
    "temp_df.to_csv('team_ids.csv')\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM team_ranks WHERE mid = '0e85fbcc-0d91-4f03-942e-c92b5fae991f'\")\n",
    "temp_df = temp.toPandas()\n",
    "temp_df.to_csv('team_ranks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_tab = spark.read.parquet(\"s3://social-research-cheating/general-stats/sum_tab_of_winners.parquet\")\n",
    "summary_tab.registerTempTable(\"summary_tab\")\n",
    "\n",
    "invalid_mids = spark.sql(\"\"\"SELECT DISTINCT mid FROM summary_tab \n",
    "                            WHERE tid_cnt > 1 AND pot_cnt >= 1\"\"\")\n",
    "invalid_mids.registerTempTable(\"invalid_mids\")\n",
    "\n",
    "# It contains the killings of 1,891 teamplay matches.\n",
    "sampled_obs = spark.sql(\"SELECT o.* FROM obs_data o JOIN invalid_mids i ON o.mid = i.mid\")\n",
    "sampled_obs.registerTempTable(\"sampled_obs\")\n",
    "\n",
    "# Add team IDs of killers.\n",
    "add_src_tids = spark.sql(\"\"\"SELECT s.*, CASE WHEN tid IS NULL THEN 'NA' ELSE tid END AS src_tid \n",
    "                            FROM sampled_obs s LEFT JOIN team_ids t ON s.mid = t.mid AND s.src = t.id\"\"\")\n",
    "add_src_tids.registerTempTable(\"add_src_tids\")\n",
    "\n",
    "add_tids = spark.sql(\"\"\"SELECT a.*, CASE WHEN tid IS NULL THEN 'NA' ELSE tid END AS dst_tid \n",
    "                        FROM add_src_tids a LEFT JOIN team_ids t ON a.mid = t.mid AND a.dst = t.id\"\"\")\n",
    "add_tids.registerTempTable(\"add_tids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|                 mid|                 src|src_tid|    m_date|pot_flag|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|21330d5b-0ba7-420...|account.175b7548e...|     23|2019-03-10|       1|\n",
      "|44925719-4ae3-421...|account.175b7548e...|     14|2019-03-10|       1|\n",
      "|0031e4e0-b475-46d...|account.175b7548e...|     20|2019-03-15|       1|\n",
      "|7ce8d183-c8e9-42f...|account.175b7548e...|      3|2019-03-08|       1|\n",
      "|c33acfa5-d4b9-428...|account.175b7548e...|     22|2019-03-10|       1|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get a list of victims for each match.\n",
    "victims = spark.sql(\"SELECT mid, dst FROM sampled_obs\")\n",
    "victims.registerTempTable(\"victims\")\n",
    "\n",
    "# Get a list of winners for each match.\n",
    "winners = spark.sql(\"\"\"SELECT DISTINCT o.mid, src, src_tid, m_date FROM add_tids o \n",
    "                       WHERE NOT EXISTS (SELECT mid, dst FROM victims v WHERE o.mid = v.mid AND o.src = v.dst)\"\"\")\n",
    "winners.registerTempTable(\"winners\")\n",
    "\n",
    "# Add the current cheating flag of players.\n",
    "add_flags = spark.sql(\"\"\"SELECT t.*, \n",
    "                         CASE WHEN cheating_flag = 1 AND m_date < start_date THEN 1 ELSE 0 END AS pot_flag \n",
    "                         FROM winners t LEFT JOIN players p ON t.src = p.id\"\"\")\n",
    "add_flags.registerTempTable(\"add_flags\")\n",
    "\n",
    "# Get a list of winners who are potential cheaters.\n",
    "pot_cheaters = spark.sql(\"SELECT * FROM add_flags WHERE pot_flag = 1 AND src_tid != 'NA'\")\n",
    "pot_cheaters.registerTempTable(\"pot_cheaters\")\n",
    "pot_cheaters.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|                 mid|                 src|src_tid|    m_date|pot_flag|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|013caebc-8504-4d7...|account.c9a9eaa2a...|     50|2019-03-07|       0|\n",
      "|013caebc-8504-4d7...|account.3e5396b91...|      6|2019-03-07|       0|\n",
      "|013caebc-8504-4d7...|account.577f76fe0...|     36|2019-03-07|       1|\n",
      "|013caebc-8504-4d7...|account.0e2dd932a...|      9|2019-03-07|       0|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|                 mid|                 src|src_tid|    m_date|pot_flag|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|f2f76e66-9fb7-40d...|account.57d64f776...|     NA|2019-03-27|       1|\n",
      "|6283fdb3-c24d-413...|account.f24c22165...|     NA|2019-03-05|       1|\n",
      "|bbe25e99-755d-4ca...|account.cdd20db96...|     NA|2019-03-04|       1|\n",
      "|99a629b2-f4e3-42e...|account.cdd20db96...|     NA|2019-03-03|       1|\n",
      "|12bcdfe5-34a4-473...|account.81f027093...|     NA|2019-03-06|       1|\n",
      "|be2c6092-f9d3-4a2...|account.c6f71a3c5...|     NA|2019-03-04|       1|\n",
      "|b62ae865-af8e-4e3...|account.9c45a718a...|     NA|2019-03-03|       1|\n",
      "|e07ee2f5-3e55-4c6...|account.dcb3d29db...|     NA|2019-03-02|       1|\n",
      "|b2c7e5a4-f0f0-48d...|account.ac666be40...|     NA|2019-03-03|       1|\n",
      "|cb84a1ce-cd19-427...|account.88cca8d42...|     NA|2019-03-04|       1|\n",
      "|093eb054-176b-4b9...|account.216ad15bd...|     NA|2019-03-01|       1|\n",
      "|3a625aed-fd57-49a...|account.8a36fc4f2...|     NA|2019-03-02|       1|\n",
      "|483a0e46-2d62-444...|account.4d2951657...|     NA|2019-03-13|       1|\n",
      "|f54ab324-6b31-474...|account.44b0bd971...|     NA|2019-03-04|       1|\n",
      "|bac58a82-62ca-485...|account.d8fc8cfc9...|     NA|2019-03-03|       1|\n",
      "|49c7f662-d993-4f1...|account.2ec6e051e...|     NA|2019-03-02|       1|\n",
      "|0e85fbcc-0d91-4f0...|account.9ccecb41a...|     NA|2019-03-06|       1|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "\n",
      "17\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|                 mid|                 src|src_tid|    m_date|pot_flag|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|013caebc-8504-4d7...|account.577f76fe0...|     36|2019-03-07|       1|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT * FROM add_flags WHERE mid = '013caebc-8504-4d71-be02-a082ddccda9a'\")\n",
    "temp.show()\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM add_flags WHERE pot_flag = 1 AND src_tid = 'NA'\")\n",
    "temp.show()\n",
    "print(temp.count())\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM pot_cheaters WHERE mid = '013caebc-8504-4d71-be02-a082ddccda9a'\")\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+--------+\n",
      "|                 mid|                 src|src_tid|src_rank|\n",
      "+--------------------+--------------------+-------+--------+\n",
      "|013caebc-8504-4d7...|account.577f76fe0...|     36|      13|\n",
      "+--------------------+--------------------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the ranks of invalid winners.\n",
    "add_ranks = spark.sql(\"\"\"SELECT w.mid, src, src_tid, \n",
    "                         CASE WHEN rank IS NULL THEN 'NA' ELSE rank END AS src_rank \n",
    "                         FROM pot_cheaters w JOIN team_ranks t ON w.mid = t.mid AND w.src_tid = t.tid \n",
    "                         WHERE rank != 1\"\"\")\n",
    "add_ranks.registerTempTable(\"add_ranks\")\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM add_ranks WHERE mid = '013caebc-8504-4d71-be02-a082ddccda9a'\")\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_tab = spark.sql(\"\"\"SELECT mid, tid, rank, \n",
    "                        LAG(tid) OVER (ORDER BY mid, rank) AS lag_tid, \n",
    "                        LAG(rank) OVER (ORDER BY mid, rank) AS lag_rank, \n",
    "                        LEAD(tid) OVER (ORDER BY mid, rank) AS lead_tid, \n",
    "                        LEAD(rank) OVER (ORDER BY mid, rank) AS lead_rank \n",
    "                        FROM team_ranks\"\"\")\n",
    "temp_tab.registerTempTable(\"temp_tab\")\n",
    "\n",
    "lag_lead_rows = spark.sql(\"\"\"SELECT a.mid, src, src_tid, src_rank, lag_tid, lag_rank, lead_tid, lead_rank \n",
    "                             FROM add_ranks a JOIN temp_tab t ON a.mid = t.mid AND a.src_tid = t.tid\"\"\")\n",
    "lag_lead_rows.registerTempTable(\"lag_lead_rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+--------+-------+--------+--------+---------+\n",
      "|                 mid|                 src|src_tid|src_rank|lag_tid|lag_rank|lead_tid|lead_rank|\n",
      "+--------------------+--------------------+-------+--------+-------+--------+--------+---------+\n",
      "|013caebc-8504-4d7...|account.577f76fe0...|     36|      13|      5|      12|       7|       13|\n",
      "+--------------------+--------------------+-------+--------+-------+--------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = spark.sql(\"SELECT * FROM lag_lead_rows WHERE mid = '013caebc-8504-4d71-be02-a082ddccda9a'\")\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the time when the last team member died for each match.\n",
    "add_lag_time = spark.sql(\"\"\"SELECT mid, src, src_tid, src_rank, \n",
    "                            lag_tid, lag_rank, lag_time, lead_tid, lead_rank \n",
    "                            FROM (SELECT l.*, time AS lag_time, \n",
    "                            ROW_NUMBER() OVER (PARTITION BY l.mid, l.src, l.src_tid ORDER BY time DESC) AS rownumber \n",
    "                            FROM lag_lead_rows l JOIN add_tids a \n",
    "                            ON l.lag_tid = a.dst_tid AND l.mid = a.mid) \n",
    "                            WHERE rownumber IN (1)\"\"\")\n",
    "add_lag_time.registerTempTable(\"add_lag_time\")\n",
    "\n",
    "add_time = spark.sql(\"\"\"SELECT mid, src, src_tid, src_rank, lag_tid, lag_rank, lag_time, \n",
    "                        lead_tid, lead_rank, lead_time \n",
    "                        FROM (SELECT l.*, time AS lead_time, \n",
    "                        ROW_NUMBER() OVER (PARTITION BY l.mid, l.src, l.src_tid ORDER BY time DESC) AS rownumber \n",
    "                        FROM add_lag_time l JOIN add_tids a ON l.lead_tid = a.dst_tid AND l.mid = a.mid) \n",
    "                        WHERE rownumber IN (1)\"\"\")\n",
    "add_time.registerTempTable(\"add_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_tsdiff = spark.sql(\"\"\"SELECT *, (UNIX_TIMESTAMP(lag_time) - UNIX_TIMESTAMP(lead_time)) AS tsdiff \n",
    "                          FROM add_time\"\"\")\n",
    "add_tsdiff.registerTempTable(\"add_tsdiff\")\n",
    "\n",
    "add_new_time = spark.sql(\"\"\"SELECT *, \n",
    "                            CASE WHEN lag_rank = 1 AND tsdiff < 0\n",
    "                            THEN TO_TIMESTAMP(FROM_UNIXTIME(UNIX_TIMESTAMP(lead_time) + 1))\n",
    "                            WHEN lead_rank = 1 THEN lag_time\n",
    "                            WHEN lead_rank != 1 AND lag_rank != 1 AND tsdiff < 0\n",
    "                            THEN TO_TIMESTAMP(FROM_UNIXTIME(UNIX_TIMESTAMP(lead_time) + 1))\n",
    "                            ELSE TO_TIMESTAMP(FROM_UNIXTIME(UNIX_TIMESTAMP(lead_time) + FLOOR(0 + (RAND() * tsdiff)))) END \n",
    "                            AS new_time\n",
    "                            FROM add_tsdiff\"\"\")\n",
    "add_new_time.registerTempTable(\"add_new_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+--------+-------+--------+--------------------+--------+---------+--------------------+------+--------------------+\n",
      "|                 mid|                 src|src_tid|src_rank|lag_tid|lag_rank|            lag_time|lead_tid|lead_rank|           lead_time|tsdiff|            new_time|\n",
      "+--------------------+--------------------+-------+--------+-------+--------+--------------------+--------+---------+--------------------+------+--------------------+\n",
      "|160b38b4-7bb1-4c2...|account.f19f20ca6...|     24|      27|     13|      27|2019-03-20 17:12:...|      23|        1|2019-03-20 17:26:...|  -851|2019-03-20 17:12:...|\n",
      "|7e6c76cb-e8f5-450...|account.5b99b526c...|     44|      47|     36|      47|2019-03-03 07:21:...|      33|        1|2019-03-03 07:31:...|  -612|2019-03-03 07:21:...|\n",
      "+--------------------+--------------------+-------+--------+-------+--------+--------------------+--------+---------+--------------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test whether the time difference is always non-negative.\n",
    "temp = spark.sql(\"\"\"SELECT * FROM add_new_time \n",
    "                    WHERE (UNIX_TIMESTAMP(new_time) - UNIX_TIMESTAMP(lead_time)) < 0\"\"\")\n",
    "temp.show()\n",
    "# temp_df = temp.toPandas()\n",
    "# temp_df.to_csv('errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = add_new_time.toPandas()\n",
    "temp_df.to_csv('new_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+----------+---------+----+----------+\n",
      "|                 mid|                  id|        sd|        bd|curr_flag|flag|    m_date|\n",
      "+--------------------+--------------------+----------+----------+---------+----+----------+\n",
      "|1d4f9928-93ba-451...|account.c8348adfe...|2019-03-03|2019-03-04|        1|   1|2019-03-03|\n",
      "|9041b53d-ce14-448...|account.2c9a1b06b...|        NA|        NA|        0|   0|2019-03-01|\n",
      "|cd295514-a3a9-469...|account.510342370...|        NA|        NA|        0|   0|2019-03-07|\n",
      "|dffc21ac-c81c-475...|account.52bd2d26e...|        NA|        NA|        0|   0|2019-03-06|\n",
      "|999ad874-66ab-4e1...|account.1de176fd4...|        NA|        NA|        0|   0|2019-03-09|\n",
      "+--------------------+--------------------+----------+----------+---------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a table that contains participant information.\n",
    "player_info = spark.sql(\"\"\"SELECT DISTINCT mid, src AS id, src_sd AS sd, src_bd AS bd, \n",
    "                           src_curr_flag AS curr_flag, src_flag AS flag, m_date \n",
    "                           FROM sampled_obs \n",
    "                           UNION \n",
    "                           SELECT DISTINCT mid, dst, dst_sd, dst_bd, \n",
    "                           dst_curr_flag, dst_flag, m_date \n",
    "                           FROM sampled_obs\"\"\")\n",
    "player_info.registerTempTable(\"player_info\")\n",
    "player_info.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create self-loops.\n",
    "self_loops = spark.sql(\"\"\"SELECT a.mid, src, sd, bd, curr_flag, flag, \n",
    "                          src, sd, bd, curr_flag, flag, new_time AS time, m_date \n",
    "                          FROM add_new_time a JOIN player_info p ON a.mid = p.mid AND a.src = p.id\"\"\")\n",
    "self_loops.registerTempTable(\"self_loops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+----------+---------+----+--------------------+----------+----------+---------+----+-------------------+----------+\n",
      "|                 mid|                 src|        sd|        bd|curr_flag|flag|                 src|        sd|        bd|curr_flag|flag|               time|    m_date|\n",
      "+--------------------+--------------------+----------+----------+---------+----+--------------------+----------+----------+---------+----+-------------------+----------+\n",
      "|013caebc-8504-4d7...|account.577f76fe0...|2019-03-08|2019-03-09|        0|   1|account.577f76fe0...|2019-03-08|2019-03-09|        0|   1|2019-03-07 11:48:19|2019-03-07|\n",
      "+--------------------+--------------------+----------+----------+---------+----+--------------------+----------+----------+---------+----+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_loops = spark.sql(\"SELECT * FROM self_loops WHERE mid = '013caebc-8504-4d71-be02-a082ddccda9a'\")\n",
    "temp_loops.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, add self-loops for the cases where winners have different team IDs including 'NA' as team ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|                 mid|                 src|src_tid|    m_date|pot_flag|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "|f2f76e66-9fb7-40d...|account.57d64f776...|     NA|2019-03-27|       1|\n",
      "|6283fdb3-c24d-413...|account.f24c22165...|     NA|2019-03-05|       1|\n",
      "|bbe25e99-755d-4ca...|account.cdd20db96...|     NA|2019-03-04|       1|\n",
      "|99a629b2-f4e3-42e...|account.cdd20db96...|     NA|2019-03-03|       1|\n",
      "|12bcdfe5-34a4-473...|account.81f027093...|     NA|2019-03-06|       1|\n",
      "+--------------------+--------------------+-------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "na_pot_cheaters = spark.sql(\"SELECT * FROM add_flags WHERE pot_flag = 1 AND src_tid = 'NA'\")\n",
    "na_pot_cheaters.registerTempTable(\"na_pot_cheaters\")\n",
    "na_pot_cheaters.show(5)\n",
    "print(na_pot_cheaters.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+----------+-------------+--------+--------------------+------+------+-------------+--------+--------------------+----------+-------+\n",
      "|                 mid|                 src|    src_sd|    src_bd|src_curr_flag|src_flag|                 dst|dst_sd|dst_bd|dst_curr_flag|dst_flag|                time|    m_date|row_num|\n",
      "+--------------------+--------------------+----------+----------+-------------+--------+--------------------+------+------+-------------+--------+--------------------+----------+-------+\n",
      "|1de898e9-65f0-4d2...|account.bcbbd1d75...|2019-03-21|2019-03-23|            0|       1|account.588c4bb15...|    NA|    NA|            0|       0|2019-03-05 11:13:...|2019-03-05|      1|\n",
      "|2450097b-8958-40e...|account.6b5cbec14...|        NA|        NA|            0|       0|account.d2a9ff1ee...|    NA|    NA|            0|       0|2019-03-05 16:54:...|2019-03-05|      1|\n",
      "|2f183c4d-ca43-41f...|account.421182046...|2019-03-10|2019-03-11|            0|       1|account.4af9528fb...|    NA|    NA|            0|       0|2019-03-08 04:26:...|2019-03-08|      1|\n",
      "|46b00f2e-9782-4b3...|account.9e57a31be...|        NA|        NA|            0|       0|account.1ce444f67...|    NA|    NA|            0|       0|2019-03-06 22:40:...|2019-03-06|      1|\n",
      "|6d5f7025-51f3-44c...|account.9ac1f9a3b...|        NA|        NA|            0|       0|account.98c0428ef...|    NA|    NA|            0|       0|2019-03-12 16:43:...|2019-03-12|      1|\n",
      "|76305f45-7c94-470...|account.d9aa3b603...|        NA|        NA|            0|       0|account.c142ae847...|    NA|    NA|            0|       0|2019-03-01 11:35:...|2019-03-01|      1|\n",
      "|d6cd1e79-c56f-4cf...|account.4bf9eed0f...|2019-03-15|2019-03-16|            0|       1|account.1576f8133...|    NA|    NA|            0|       0|2019-03-12 17:23:...|2019-03-12|      1|\n",
      "|d9aa1e38-7bb8-41a...|account.bf26a821b...|2019-03-28|2019-03-31|            0|       1|account.b7aaab949...|    NA|    NA|            0|       0|2019-03-02 03:44:...|2019-03-02|      1|\n",
      "|e690b59f-824f-44d...|account.98add8861...|        NA|        NA|            0|       0|account.c3ce48717...|    NA|    NA|            0|       0|2019-03-05 10:35:...|2019-03-05|      1|\n",
      "|06f1e3b7-52ec-476...|account.f38208eab...|2019-03-09|2019-03-10|            0|       1|account.8d3ac4390...|    NA|    NA|            0|       0|2019-03-02 20:49:...|2019-03-02|      1|\n",
      "+--------------------+--------------------+----------+----------+-------------+--------+--------------------+------+------+-------------+--------+--------------------+----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the last kill of each match.\n",
    "last_kills = spark.sql(\"\"\"SELECT * \n",
    "                          FROM (SELECT o.*, ROW_NUMBER() OVER (PARTITION BY mid ORDER BY time DESC) AS row_num \n",
    "                                FROM sampled_obs AS o) \n",
    "                          WHERE row_num = 1\"\"\")\n",
    "last_kills.registerTempTable(\"last_kills\")\n",
    "last_kills.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+----------+-------------+--------+--------------------+------+------+-------------+--------+--------------------+----------+-------+\n",
      "|                 mid|                 src|    src_sd|    src_bd|src_curr_flag|src_flag|                 dst|dst_sd|dst_bd|dst_curr_flag|dst_flag|                time|    m_date|row_num|\n",
      "+--------------------+--------------------+----------+----------+-------------+--------+--------------------+------+------+-------------+--------+--------------------+----------+-------+\n",
      "|be2c6092-f9d3-4a2...|account.c6f71a3c5...|2019-03-18|2019-03-30|            0|       1|account.a18547acf...|    NA|    NA|            0|       0|2019-03-04 18:50:...|2019-03-04|      1|\n",
      "|bac58a82-62ca-485...|account.d8fc8cfc9...|2019-03-05|2019-03-06|            0|       1|account.0c3829c84...|    NA|    NA|            0|       0|2019-03-03 17:42:...|2019-03-03|      1|\n",
      "|093eb054-176b-4b9...|account.216ad15bd...|2019-03-02|2019-03-03|            0|       1|account.08cc12fd3...|    NA|    NA|            0|       0|2019-03-01 18:27:...|2019-03-01|      1|\n",
      "|f54ab324-6b31-474...|account.44b0bd971...|2019-03-05|2019-03-06|            0|       1|account.f7e5f7026...|    NA|    NA|            0|       0|2019-03-04 15:46:...|2019-03-04|      1|\n",
      "|f2f76e66-9fb7-40d...|account.57d64f776...|2019-03-30|2019-03-31|            0|       1|account.7b1dab2e0...|    NA|    NA|            0|       0|2019-03-27 08:41:...|2019-03-27|      1|\n",
      "|cb84a1ce-cd19-427...|account.88cca8d42...|2019-03-05|2019-03-06|            0|       1|account.db6b23116...|    NA|    NA|            0|       0|2019-03-04 21:40:...|2019-03-04|      1|\n",
      "|6283fdb3-c24d-413...|account.f24c22165...|2019-03-08|2019-03-09|            0|       1|account.0e00c1244...|    NA|    NA|            0|       0|2019-03-05 15:50:...|2019-03-05|      1|\n",
      "|49c7f662-d993-4f1...|account.2ec6e051e...|2019-03-04|2019-03-05|            0|       1|account.40bf78f25...|    NA|    NA|            0|       0|2019-03-02 21:04:...|2019-03-02|      1|\n",
      "|b62ae865-af8e-4e3...|account.9c45a718a...|2019-03-07|2019-03-12|            0|       1|account.4f93e91f6...|    NA|    NA|            0|       0|2019-03-03 21:27:...|2019-03-03|      1|\n",
      "|12bcdfe5-34a4-473...|account.81f027093...|2019-03-15|2019-03-16|            0|       1|account.a96309849...|    NA|    NA|            0|       0|2019-03-06 12:20:...|2019-03-06|      1|\n",
      "|0e85fbcc-0d91-4f0...|account.9ccecb41a...|2019-03-07|2019-03-08|            0|       1|account.4997d46f9...|    NA|    NA|            0|       0|2019-03-06 10:15:...|2019-03-06|      1|\n",
      "|b2c7e5a4-f0f0-48d...|account.ac666be40...|2019-03-08|2019-03-09|            0|       1|account.f6267fddb...|    NA|    NA|            0|       0|2019-03-03 20:26:...|2019-03-03|      1|\n",
      "|3a625aed-fd57-49a...|account.8a36fc4f2...|2019-03-10|2019-03-11|            0|       1|account.4ce125e64...|    NA|    NA|            0|       0|2019-03-02 18:42:...|2019-03-02|      1|\n",
      "|483a0e46-2d62-444...|account.4d2951657...|2019-03-14|2019-03-14|            0|       1|account.a4b0ea081...|    NA|    NA|            0|       0|2019-03-13 08:19:...|2019-03-13|      1|\n",
      "|bbe25e99-755d-4ca...|account.cdd20db96...|2019-03-06|2019-03-07|            0|       1|account.cd42e59d1...|    NA|    NA|            0|       0|2019-03-04 12:33:...|2019-03-04|      1|\n",
      "|99a629b2-f4e3-42e...|account.cdd20db96...|2019-03-06|2019-03-07|            0|       1|account.13ff8f407...|    NA|    NA|            0|       0|2019-03-03 13:59:...|2019-03-03|      1|\n",
      "|e07ee2f5-3e55-4c6...|account.dcb3d29db...|2019-03-03|2019-03-05|            0|       1|account.c4581df48...|    NA|    NA|            0|       0|2019-03-02 13:37:...|2019-03-02|      1|\n",
      "+--------------------+--------------------+----------+----------+-------------+--------+--------------------+------+------+-------------+--------+--------------------+----------+-------+\n",
      "\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "# Find the last kill of each winner whose team ID is 'NA'.\n",
    "na_player_kills = spark.sql(\"\"\"SELECT * \n",
    "                               FROM (SELECT o.*, \n",
    "                                     ROW_NUMBER() OVER (PARTITION BY w.mid, w.src ORDER BY time DESC) AS row_num \n",
    "                                     FROM sampled_obs o JOIN na_pot_cheaters w \n",
    "                                     ON o.mid = w.mid AND o.src = w.src) \n",
    "                              WHERE row_num = 1\"\"\")\n",
    "na_player_kills.registerTempTable(\"na_player_kills\")\n",
    "na_player_kills.show()\n",
    "print(na_player_kills.count()) # The result should be 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+--------------------+----------+------+\n",
      "|                 mid|                 src|src_curr_flag|                time|    m_date|tsdiff|\n",
      "+--------------------+--------------------+-------------+--------------------+----------+------+\n",
      "|f2f76e66-9fb7-40d...|account.57d64f776...|            0|2019-03-27 08:41:...|2019-03-27|  1676|\n",
      "|0e85fbcc-0d91-4f0...|account.9ccecb41a...|            0|2019-03-06 10:15:...|2019-03-06|     0|\n",
      "|b2c7e5a4-f0f0-48d...|account.ac666be40...|            0|2019-03-03 20:26:...|2019-03-03|   374|\n",
      "|bac58a82-62ca-485...|account.d8fc8cfc9...|            0|2019-03-03 17:42:...|2019-03-03|    44|\n",
      "|f54ab324-6b31-474...|account.44b0bd971...|            0|2019-03-04 15:46:...|2019-03-04|     0|\n",
      "|483a0e46-2d62-444...|account.4d2951657...|            0|2019-03-13 08:19:...|2019-03-13|     0|\n",
      "|bbe25e99-755d-4ca...|account.cdd20db96...|            0|2019-03-04 12:33:...|2019-03-04|  1497|\n",
      "|cb84a1ce-cd19-427...|account.88cca8d42...|            0|2019-03-04 21:40:...|2019-03-04|   871|\n",
      "|6283fdb3-c24d-413...|account.f24c22165...|            0|2019-03-05 15:50:...|2019-03-05|  1208|\n",
      "|b62ae865-af8e-4e3...|account.9c45a718a...|            0|2019-03-03 21:27:...|2019-03-03|     0|\n",
      "|99a629b2-f4e3-42e...|account.cdd20db96...|            0|2019-03-03 13:59:...|2019-03-03|  1259|\n",
      "|be2c6092-f9d3-4a2...|account.c6f71a3c5...|            0|2019-03-04 18:50:...|2019-03-04|   893|\n",
      "|093eb054-176b-4b9...|account.216ad15bd...|            0|2019-03-01 18:27:...|2019-03-01|   232|\n",
      "|49c7f662-d993-4f1...|account.2ec6e051e...|            0|2019-03-02 21:04:...|2019-03-02|     0|\n",
      "|3a625aed-fd57-49a...|account.8a36fc4f2...|            0|2019-03-02 18:42:...|2019-03-02|   136|\n",
      "|12bcdfe5-34a4-473...|account.81f027093...|            0|2019-03-06 12:20:...|2019-03-06|   235|\n",
      "|e07ee2f5-3e55-4c6...|account.dcb3d29db...|            0|2019-03-02 13:37:...|2019-03-02|   789|\n",
      "+--------------------+--------------------+-------------+--------------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a new random time for each self-loop.\n",
    "cal_tsdiff = spark.sql(\"\"\"SELECT n.mid, n.src, n.time,  \n",
    "                          (UNIX_TIMESTAMP(l.time) - UNIX_TIMESTAMP(n.time)) AS tsdiff\n",
    "                          FROM na_player_kills n JOIN last_kills l ON n.mid = l.mid\"\"\")\n",
    "cal_tsdiff.registerTempTable(\"cal_tsdiff\")\n",
    "cal_tsdiff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+--------------------+----------+------+-------------------+\n",
      "|                 mid|                 src|src_curr_flag|                time|    m_date|tsdiff|           new_time|\n",
      "+--------------------+--------------------+-------------+--------------------+----------+------+-------------------+\n",
      "|f2f76e66-9fb7-40d...|account.57d64f776...|            0|2019-03-27 08:41:...|2019-03-27|  1676|2019-03-27 09:05:07|\n",
      "|0e85fbcc-0d91-4f0...|account.9ccecb41a...|            0|2019-03-06 10:15:...|2019-03-06|     0|               null|\n",
      "|b2c7e5a4-f0f0-48d...|account.ac666be40...|            0|2019-03-03 20:26:...|2019-03-03|   374|2019-03-03 20:28:39|\n",
      "|bac58a82-62ca-485...|account.d8fc8cfc9...|            0|2019-03-03 17:42:...|2019-03-03|    44|2019-03-03 17:42:09|\n",
      "|f54ab324-6b31-474...|account.44b0bd971...|            0|2019-03-04 15:46:...|2019-03-04|     0|               null|\n",
      "|483a0e46-2d62-444...|account.4d2951657...|            0|2019-03-13 08:19:...|2019-03-13|     0|               null|\n",
      "|bbe25e99-755d-4ca...|account.cdd20db96...|            0|2019-03-04 12:33:...|2019-03-04|  1497|2019-03-04 12:56:16|\n",
      "|cb84a1ce-cd19-427...|account.88cca8d42...|            0|2019-03-04 21:40:...|2019-03-04|   871|2019-03-04 21:46:54|\n",
      "|6283fdb3-c24d-413...|account.f24c22165...|            0|2019-03-05 15:50:...|2019-03-05|  1208|2019-03-05 15:51:44|\n",
      "|b62ae865-af8e-4e3...|account.9c45a718a...|            0|2019-03-03 21:27:...|2019-03-03|     0|               null|\n",
      "|99a629b2-f4e3-42e...|account.cdd20db96...|            0|2019-03-03 13:59:...|2019-03-03|  1259|2019-03-03 14:19:20|\n",
      "|be2c6092-f9d3-4a2...|account.c6f71a3c5...|            0|2019-03-04 18:50:...|2019-03-04|   893|2019-03-04 18:54:04|\n",
      "|093eb054-176b-4b9...|account.216ad15bd...|            0|2019-03-01 18:27:...|2019-03-01|   232|2019-03-01 18:27:44|\n",
      "|49c7f662-d993-4f1...|account.2ec6e051e...|            0|2019-03-02 21:04:...|2019-03-02|     0|               null|\n",
      "|3a625aed-fd57-49a...|account.8a36fc4f2...|            0|2019-03-02 18:42:...|2019-03-02|   136|2019-03-02 18:44:23|\n",
      "|12bcdfe5-34a4-473...|account.81f027093...|            0|2019-03-06 12:20:...|2019-03-06|   235|2019-03-06 12:23:34|\n",
      "|e07ee2f5-3e55-4c6...|account.dcb3d29db...|            0|2019-03-02 13:37:...|2019-03-02|   789|2019-03-02 13:47:30|\n",
      "+--------------------+--------------------+-------------+--------------------+----------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "add_rand_time = spark.sql(\"\"\"SELECT c.*,  \n",
    "                             CASE WHEN tsdiff = 0 THEN NULL\n",
    "                             ELSE TO_TIMESTAMP(FROM_UNIXTIME(UNIX_TIMESTAMP(time) + FLOOR(0 + (RAND() * tsdiff)))) END \n",
    "                             AS new_time\n",
    "                             FROM cal_tsdiff AS c\"\"\")\n",
    "add_rand_time.registerTempTable(\"add_rand_time\")\n",
    "add_rand_time.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+--------------------+----------+------+-------------------+\n",
      "|                 mid|                 src|src_curr_flag|                time|    m_date|tsdiff|           new_time|\n",
      "+--------------------+--------------------+-------------+--------------------+----------+------+-------------------+\n",
      "|f2f76e66-9fb7-40d...|account.57d64f776...|            0|2019-03-27 08:41:...|2019-03-27|  1676|2019-03-27 09:05:07|\n",
      "|b2c7e5a4-f0f0-48d...|account.ac666be40...|            0|2019-03-03 20:26:...|2019-03-03|   374|2019-03-03 20:28:39|\n",
      "|bac58a82-62ca-485...|account.d8fc8cfc9...|            0|2019-03-03 17:42:...|2019-03-03|    44|2019-03-03 17:42:09|\n",
      "|bbe25e99-755d-4ca...|account.cdd20db96...|            0|2019-03-04 12:33:...|2019-03-04|  1497|2019-03-04 12:56:16|\n",
      "|cb84a1ce-cd19-427...|account.88cca8d42...|            0|2019-03-04 21:40:...|2019-03-04|   871|2019-03-04 21:46:54|\n",
      "|6283fdb3-c24d-413...|account.f24c22165...|            0|2019-03-05 15:50:...|2019-03-05|  1208|2019-03-05 15:51:44|\n",
      "|99a629b2-f4e3-42e...|account.cdd20db96...|            0|2019-03-03 13:59:...|2019-03-03|  1259|2019-03-03 14:19:20|\n",
      "|be2c6092-f9d3-4a2...|account.c6f71a3c5...|            0|2019-03-04 18:50:...|2019-03-04|   893|2019-03-04 18:54:04|\n",
      "|093eb054-176b-4b9...|account.216ad15bd...|            0|2019-03-01 18:27:...|2019-03-01|   232|2019-03-01 18:27:44|\n",
      "|3a625aed-fd57-49a...|account.8a36fc4f2...|            0|2019-03-02 18:42:...|2019-03-02|   136|2019-03-02 18:44:23|\n",
      "|12bcdfe5-34a4-473...|account.81f027093...|            0|2019-03-06 12:20:...|2019-03-06|   235|2019-03-06 12:23:34|\n",
      "|e07ee2f5-3e55-4c6...|account.dcb3d29db...|            0|2019-03-02 13:37:...|2019-03-02|   789|2019-03-02 13:47:30|\n",
      "+--------------------+--------------------+-------------+--------------------+----------+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove the rows with NULL values.\n",
    "add_rand_time = spark.sql(\"SELECT * FROM add_rand_time WHERE new_time IS NOT NULL\")\n",
    "add_rand_time.registerTempTable(\"add_rand_time\")\n",
    "add_rand_time.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+----------+---------+----+--------------------+----------+----------+---------+----+-------------------+----------+\n",
      "|                 mid|                 src|        sd|        bd|curr_flag|flag|                 src|        sd|        bd|curr_flag|flag|               time|    m_date|\n",
      "+--------------------+--------------------+----------+----------+---------+----+--------------------+----------+----------+---------+----+-------------------+----------+\n",
      "|be2c6092-f9d3-4a2...|account.c6f71a3c5...|2019-03-18|2019-03-30|        0|   1|account.c6f71a3c5...|2019-03-18|2019-03-30|        0|   1|2019-03-04 18:54:04|2019-03-04|\n",
      "|bac58a82-62ca-485...|account.d8fc8cfc9...|2019-03-05|2019-03-06|        0|   1|account.d8fc8cfc9...|2019-03-05|2019-03-06|        0|   1|2019-03-03 17:42:09|2019-03-03|\n",
      "|093eb054-176b-4b9...|account.216ad15bd...|2019-03-02|2019-03-03|        0|   1|account.216ad15bd...|2019-03-02|2019-03-03|        0|   1|2019-03-01 18:27:44|2019-03-01|\n",
      "|f2f76e66-9fb7-40d...|account.57d64f776...|2019-03-30|2019-03-31|        0|   1|account.57d64f776...|2019-03-30|2019-03-31|        0|   1|2019-03-27 09:05:07|2019-03-27|\n",
      "|cb84a1ce-cd19-427...|account.88cca8d42...|2019-03-05|2019-03-06|        0|   1|account.88cca8d42...|2019-03-05|2019-03-06|        0|   1|2019-03-04 21:46:54|2019-03-04|\n",
      "|6283fdb3-c24d-413...|account.f24c22165...|2019-03-08|2019-03-09|        0|   1|account.f24c22165...|2019-03-08|2019-03-09|        0|   1|2019-03-05 15:51:44|2019-03-05|\n",
      "|12bcdfe5-34a4-473...|account.81f027093...|2019-03-15|2019-03-16|        0|   1|account.81f027093...|2019-03-15|2019-03-16|        0|   1|2019-03-06 12:23:34|2019-03-06|\n",
      "|b2c7e5a4-f0f0-48d...|account.ac666be40...|2019-03-08|2019-03-09|        0|   1|account.ac666be40...|2019-03-08|2019-03-09|        0|   1|2019-03-03 20:28:39|2019-03-03|\n",
      "|3a625aed-fd57-49a...|account.8a36fc4f2...|2019-03-10|2019-03-11|        0|   1|account.8a36fc4f2...|2019-03-10|2019-03-11|        0|   1|2019-03-02 18:44:23|2019-03-02|\n",
      "|bbe25e99-755d-4ca...|account.cdd20db96...|2019-03-06|2019-03-07|        0|   1|account.cdd20db96...|2019-03-06|2019-03-07|        0|   1|2019-03-04 12:56:16|2019-03-04|\n",
      "|99a629b2-f4e3-42e...|account.cdd20db96...|2019-03-06|2019-03-07|        0|   1|account.cdd20db96...|2019-03-06|2019-03-07|        0|   1|2019-03-03 14:19:20|2019-03-03|\n",
      "|e07ee2f5-3e55-4c6...|account.dcb3d29db...|2019-03-03|2019-03-05|        0|   1|account.dcb3d29db...|2019-03-03|2019-03-05|        0|   1|2019-03-02 13:47:30|2019-03-02|\n",
      "+--------------------+--------------------+----------+----------+---------+----+--------------------+----------+----------+---------+----+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create self-loops.\n",
    "rand_self_loops = spark.sql(\"\"\"SELECT a.mid, src, sd, bd, curr_flag, flag, \n",
    "                               src, sd, bd, curr_flag, flag, new_time AS time, m_date \n",
    "                               FROM add_rand_time a JOIN player_info p \n",
    "                               ON a.mid = p.mid AND a.src = p.id\"\"\")\n",
    "rand_self_loops.registerTempTable(\"rand_self_loops\")\n",
    "rand_self_loops.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+----------+---------+----+--------------------+----------+----------+---------+----+-------------------+----------+\n",
      "|                 mid|                 src|        sd|        bd|curr_flag|flag|                 src|        sd|        bd|curr_flag|flag|               time|    m_date|\n",
      "+--------------------+--------------------+----------+----------+---------+----+--------------------+----------+----------+---------+----+-------------------+----------+\n",
      "|1b9c6a48-b81f-4f6...|account.78f9c3700...|2019-03-08|2019-03-09|        0|   1|account.78f9c3700...|2019-03-08|2019-03-09|        0|   1|2019-03-05 15:40:59|2019-03-05|\n",
      "|11a69c34-647b-4fa...|account.57d44119f...|2019-03-08|2019-03-09|        0|   1|account.57d44119f...|2019-03-08|2019-03-09|        0|   1|2019-03-02 16:55:43|2019-03-02|\n",
      "|28bca936-a425-492...|account.078af237a...|2019-03-25|2019-03-26|        0|   1|account.078af237a...|2019-03-25|2019-03-26|        0|   1|2019-03-17 11:46:56|2019-03-17|\n",
      "|1b4b29f9-f7d3-490...|account.b9c9ec0de...|2019-03-14|2019-03-14|        0|   1|account.b9c9ec0de...|2019-03-14|2019-03-14|        0|   1|2019-03-01 05:33:43|2019-03-01|\n",
      "|0113f4ea-ae7c-459...|account.c065b439c...|2019-03-06|2019-03-07|        0|   1|account.c065b439c...|2019-03-06|2019-03-07|        0|   1|2019-03-01 22:31:46|2019-03-01|\n",
      "|90ec763d-953f-46f...|account.1e6a58ad1...|2019-03-22|2019-03-30|        0|   1|account.1e6a58ad1...|2019-03-22|2019-03-30|        0|   1|2019-03-11 09:22:45|2019-03-11|\n",
      "|36c4d560-98d7-408...|account.e7c02a14c...|2019-03-22|2019-03-23|        0|   1|account.e7c02a14c...|2019-03-22|2019-03-23|        0|   1|2019-03-21 20:53:30|2019-03-21|\n",
      "|ebfcf5eb-5e0c-4a1...|account.dbbfe2a9a...|2019-03-12|2019-03-13|        0|   1|account.dbbfe2a9a...|2019-03-12|2019-03-13|        0|   1|2019-03-04 11:34:58|2019-03-04|\n",
      "|2c31277e-01bc-4a1...|account.43ce956d7...|2019-03-04|2019-03-05|        0|   1|account.43ce956d7...|2019-03-04|2019-03-05|        0|   1|2019-03-03 16:36:02|2019-03-03|\n",
      "|b62ae865-af8e-4e3...|account.e945a702f...|2019-03-04|2019-03-05|        0|   1|account.e945a702f...|2019-03-04|2019-03-05|        0|   1|2019-03-03 21:23:45|2019-03-03|\n",
      "|73f728e7-a392-4bb...|account.d1d1a3eb5...|2019-03-11|2019-03-12|        0|   1|account.d1d1a3eb5...|2019-03-11|2019-03-12|        0|   1|2019-03-10 11:17:42|2019-03-10|\n",
      "|d4cc5f6d-e5b6-46b...|account.c5ffb82e3...|2019-03-07|2019-03-07|        0|   1|account.c5ffb82e3...|2019-03-07|2019-03-07|        0|   1|2019-03-06 16:33:17|2019-03-06|\n",
      "|f5591c24-2110-456...|account.2c44ed2f0...|2019-03-29|2019-03-30|        0|   1|account.2c44ed2f0...|2019-03-29|2019-03-30|        0|   1|2019-03-14 19:49:31|2019-03-14|\n",
      "|c13aeac1-f6a4-449...|account.aad5f6cc2...|2019-03-06|2019-03-15|        0|   1|account.aad5f6cc2...|2019-03-06|2019-03-15|        0|   1|2019-03-04 22:08:27|2019-03-04|\n",
      "|5367fb10-34cf-48c...|account.2d772a6a1...|2019-03-13|2019-03-24|        0|   1|account.2d772a6a1...|2019-03-13|2019-03-24|        0|   1|2019-03-06 05:59:36|2019-03-06|\n",
      "|8bf5f77e-9fc4-4d1...|account.f11409269...|2019-03-25|2019-03-26|        0|   1|account.f11409269...|2019-03-25|2019-03-26|        0|   1|2019-03-22 22:44:44|2019-03-22|\n",
      "|b9770300-bd22-44c...|account.317dd97d7...|2019-03-10|2019-03-11|        0|   1|account.317dd97d7...|2019-03-10|2019-03-11|        0|   1|2019-03-05 20:09:27|2019-03-05|\n",
      "|d58da375-7af2-4db...|account.8a36fc4f2...|2019-03-10|2019-03-11|        0|   1|account.8a36fc4f2...|2019-03-10|2019-03-11|        0|   1|2019-03-04 20:53:51|2019-03-04|\n",
      "|72cfb632-4d19-410...|account.47ff35eca...|2019-03-02|2019-03-03|        0|   1|account.47ff35eca...|2019-03-02|2019-03-03|        0|   1|2019-03-01 09:37:55|2019-03-01|\n",
      "|7a6319b3-6032-459...|account.b89e69526...|2019-03-27|2019-03-28|        0|   1|account.b89e69526...|2019-03-27|2019-03-28|        0|   1|2019-03-04 07:43:03|2019-03-04|\n",
      "+--------------------+--------------------+----------+----------+---------+----+--------------------+----------+----------+---------+----+-------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "715\n"
     ]
    }
   ],
   "source": [
    "# Combine two sets of self-loops.\n",
    "full_self_loops = spark.sql(\"SELECT * FROM self_loops UNION SELECT * FROM rand_self_loops\")\n",
    "full_self_loops.registerTempTable(\"full_self_loops\")\n",
    "print(full_self_loops.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add self-loops into the original 'obs_data' dataset.\n",
    "obs_data = spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\")\n",
    "obs_data.registerTempTable(\"obs_data\")\n",
    "\n",
    "rev_obs = spark.sql(\"SELECT * FROM obs_data UNION SELECT * FROM full_self_loops ORDER BY mid, time\")\n",
    "rev_obs.registerTempTable(\"rev_obs\")\n",
    "rev_obs.write.parquet(\"s3://social-research-cheating/edges/rev_obs_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the new dataset with extra self-loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_obs = spark.read.parquet(\"s3://social-research-cheating/edges/rev_obs_data.parquet\")\n",
    "rev_obs.registerTempTable(\"rev_obs\")\n",
    "\n",
    "# Create a file for testing.\n",
    "temp = spark.sql(\"SELECT * FROM rev_obs WHERE mid = '013caebc-8504-4d71-be02-a082ddccda9a'\")\n",
    "temp_df = temp.toPandas()\n",
    "temp_df.to_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+-------+-------+\n",
      "|                 mid|winner_cnt|tid_cnt|pot_cnt|na_flag|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "|0143e2da-14d2-4d8...|         9|      6|      0|      0|\n",
      "|036a8903-186b-45f...|         4|      2|      0|      0|\n",
      "|080d5622-6b94-4d7...|         3|      2|      0|      0|\n",
      "|0c7d472e-5064-4d4...|         2|      2|      0|      0|\n",
      "|0ef25288-88d3-476...|         2|      1|      0|      0|\n",
      "|1203abce-50ec-40d...|         4|      4|      0|      0|\n",
      "|1574a6bb-a63f-473...|         5|      2|      0|      0|\n",
      "|16d6f605-4118-4de...|         4|      3|      0|      0|\n",
      "|1773f8d7-b807-439...|         3|      2|      0|      0|\n",
      "|194e1d81-b65c-4dc...|         4|      2|      0|      0|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "team_ids = spark.read.parquet(\"s3://social-research-cheating/edges/tiny_team_data.parquet\")\n",
    "team_ids.registerTempTable(\"team_ids\")\n",
    "\n",
    "players = spark.read.parquet(\"s3://social-research-cheating/nodes.parquet\")\n",
    "players.registerTempTable(\"players\")\n",
    "\n",
    "# Get a list of mids and m_dates.\n",
    "match_info = spark.sql(\"SELECT DISTINCT mid, m_date FROM rev_obs\")\n",
    "match_info.registerTempTable(\"match_info\")\n",
    "\n",
    "# Get a list of victims for each match.\n",
    "victims = spark.sql(\"SELECT DISTINCT mid, dst FROM rev_obs\")\n",
    "victims.registerTempTable(\"victims\")\n",
    "\n",
    "# Get a list of winners for each match.\n",
    "winners = spark.sql(\"\"\"SELECT DISTINCT o.mid, src FROM rev_obs o \n",
    "                       WHERE NOT EXISTS (SELECT mid, dst FROM victims v WHERE o.mid = v.mid AND o.src = v.dst)\"\"\")\n",
    "winners.registerTempTable(\"winners\")\n",
    "\n",
    "# Add team information.\n",
    "add_tids = spark.sql(\"\"\"SELECT w.mid, src, CASE WHEN tid IS NULL THEN 'NA' ELSE tid END AS src_tid\n",
    "                        FROM winners w LEFT JOIN team_ids t ON w.mid = t.mid AND w.src = t.id\"\"\")\n",
    "add_tids.registerTempTable(\"add_tids\")\n",
    "\n",
    "# Add m_dates.\n",
    "temp_tab = spark.sql(\"\"\"SELECT a.mid, src, src_tid, m_date \n",
    "                        FROM add_tids a LEFT JOIN match_info m ON a.mid = m.mid\"\"\")\n",
    "temp_tab.registerTempTable(\"temp_tab\")\n",
    "\n",
    "# Find the matches where at least one winner's team ID is 'NA'.\n",
    "na_tids = spark.sql(\"SELECT DISTINCT mid FROM add_tids WHERE src_tid = 'NA'\")\n",
    "na_tids.registerTempTable(\"na_tids\")\n",
    "\n",
    "# Add the current cheating flag of players.\n",
    "winners = spark.sql(\"\"\"SELECT t.*, \n",
    "                       CASE WHEN cheating_flag = 1 AND m_date < start_date THEN 1 ELSE 0 END AS pot_flag \n",
    "                       FROM temp_tab t LEFT JOIN players p ON t.src = p.id\"\"\")\n",
    "winners.registerTempTable(\"winners\")\n",
    "\n",
    "# Count the number of winners and that of unique times for each match. \n",
    "cnt_tab = spark.sql(\"\"\"SELECT mid, COUNT(src) AS winner_cnt, \n",
    "                       COUNT(DISTINCT src_tid) AS tid_cnt, SUM(pot_flag) AS pot_cnt \n",
    "                       FROM winners GROUP BY mid\"\"\")\n",
    "cnt_tab.registerTempTable(\"cnt_tab\")\n",
    "\n",
    "summary_tab = spark.sql(\"\"\"SELECT c.mid, winner_cnt, tid_cnt, pot_cnt, \n",
    "                           CASE WHEN n.mid IS NULL THEN 0 ELSE 1 END AS na_flag \n",
    "                           FROM cnt_tab c LEFT JOIN na_tids n ON c.mid = n.mid\"\"\")\n",
    "summary_tab.registerTempTable(\"summary_tab\")\n",
    "summary_tab.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
