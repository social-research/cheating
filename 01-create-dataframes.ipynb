{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Create a table for each data in parquet format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We use **six datasets** for different purposes in this project.\n",
    "\n",
    "1. Dataset that contains player (node) data\n",
    "* Dataset that contains raw telemetry data for general statistics\n",
    "* Dataset for cheater analysis\n",
    "* Dataset that contains the team IDs of players who took part in teamplay matches \n",
    "* Dataset for estimating the start date of cheating and analysing the victimisation-based mechanism\n",
    "* Dataset for analysing the observation-based mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from pyspark.sql.types import StructField, StructType, StringType, IntegerType, TimestampType\n",
    "import pubg_analysis as pubg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a dataset that contains player data.\n",
    "\n",
    "The table below describes the variables in the player data:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| id         | ID of the player               \n",
    "| pname      | nickname of the player  \n",
    "| cheating_flag     | 1 if the player was banned, 0 otherwise\n",
    "| ban_date   | date in the format YYYY-MM-DD when the cheater was banned \n",
    "\n",
    "As shown below, there are 1,977,329 unique players and 6,161 players among them are cheaters in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------------+--------+\n",
      "|                  id|          pname|cheating_flag|ban_date|\n",
      "+--------------------+---------------+-------------+--------+\n",
      "|account.1d0281ff2...|      ulimnet10|            0|      NA|\n",
      "|account.1c295c6c0...|       yoon9242|            0|      NA|\n",
      "|account.a2b8791d5...|        meco001|            0|      NA|\n",
      "|account.e3b1eb159...|         forsir|            0|      NA|\n",
      "|account.65433d8ee...|      jimin0311|            0|      NA|\n",
      "|account.74c0462cd...|namyoonwoo07074|            0|      NA|\n",
      "|account.64d031587...|       wreu1234|            0|      NA|\n",
      "|account.7f874085e...|        kbs4799|            0|      NA|\n",
      "|account.5c8366a6b...|       ssabu110|            0|      NA|\n",
      "|account.d89f4429c...|      gusrb0187|            0|      NA|\n",
      "+--------------------+---------------+-------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the structure of player data.\n",
    "nodeSchema = StructType([StructField(\"id\", StringType(), True),\n",
    "                         StructField(\"pname\", StringType(), True),\n",
    "                         StructField(\"cheating_flag\", IntegerType(), True),\n",
    "                         StructField(\"ban_date\", StringType(), True)])\n",
    "\n",
    "# Create a table of player data and store it in the S3 bucket.\n",
    "PATH_TO_FILE = \"s3://social-research-cheating/td_nodes.txt\"\n",
    "\n",
    "players = spark.read.options(header='false', delimiter='\\t').schema(nodeSchema).csv(PATH_TO_FILE)\n",
    "players.write.parquet(\"s3://social-research-cheating/players.parquet\")\n",
    "players.registerTempTable(\"players\")\n",
    "\n",
    "# Show the top 10 rows of the dataset.\n",
    "players.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1977329\n",
      "+------------------+\n",
      "|count(DISTINCT id)|\n",
      "+------------------+\n",
      "|           1977329|\n",
      "+------------------+\n",
      "\n",
      "+------------------+\n",
      "|count(DISTINCT id)|\n",
      "+------------------+\n",
      "|              6161|\n",
      "+------------------+\n",
      "\n",
      "6161\n"
     ]
    }
   ],
   "source": [
    "# Count the number of players and check whether there are any duplicates.\n",
    "print(players.count())\n",
    "\n",
    "test_players = spark.sql(\"SELECT COUNT(DISTINCT id) FROM players\")\n",
    "test_players.show()\n",
    "\n",
    "# Count the number of cheaters and check whether there are any duplicates.\n",
    "test_players = spark.sql(\"\"\"SELECT COUNT(DISTINCT id) FROM players \n",
    "                            WHERE cheating_flag = 1\"\"\")\n",
    "test_players.show()\n",
    "\n",
    "cheaters = spark.sql(\"SELECT * FROM players WHERE cheating_flag = 1\")\n",
    "cheaters.registerTempTable(\"cheaters\")\n",
    "print(cheaters.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|  ban_date|num_of_cheaters|\n",
      "+----------+---------------+\n",
      "|2019-03-03|            258|\n",
      "|2019-03-11|            511|\n",
      "|2019-03-28|             99|\n",
      "|2019-03-07|            262|\n",
      "|2019-03-20|            112|\n",
      "|2019-03-19|            116|\n",
      "|2019-03-01|            103|\n",
      "|2019-03-23|            176|\n",
      "|2019-03-30|             93|\n",
      "|2019-03-16|            107|\n",
      "|2019-03-05|            228|\n",
      "|2019-03-29|            114|\n",
      "|2019-03-25|             89|\n",
      "|2019-03-31|             89|\n",
      "|2019-03-14|            139|\n",
      "|2019-03-15|            132|\n",
      "|2019-03-10|            135|\n",
      "|2019-03-17|            144|\n",
      "|2019-03-22|            118|\n",
      "|2019-03-26|            170|\n",
      "+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of cheaters by ban date.\n",
    "num_of_cheaters = spark.sql(\"\"\"SELECT ban_date, COUNT(*) AS num_of_cheaters \n",
    "                               FROM cheaters GROUP BY ban_date\"\"\")\n",
    "num_of_cheaters.show()\n",
    "\n",
    "# Store the table in the S3 bucket for the later use (plotting general statistics).\n",
    "num_of_cheaters.write.parquet(\"s3://social-research-cheating/general-stats/num_of_cheaters.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a raw dataset that contains killings. \n",
    "\n",
    "This dataset will be used for general statistics.\n",
    "\n",
    "The table below describes the variables in the telemetry data:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid         | ID of the match               \n",
    "| src      | ID of the killer  \n",
    "| dst     | ID of the victim \n",
    "| time   | time in the format YYYY-MM-DD HH:MM:SS.SSS Z when the attack (killing) happened\n",
    "| m_date   | date in the format YYYY-MM-DD when the match was played \n",
    "\n",
    "There are 1,146,941 unique matches played during the observation period.<br>\n",
    "The total number of killings (edges) including self-loops in the dataset is 98,319,451."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_nums = [(1, 7), (2, 7), (3, 7), (4, 4), (5, 4), \n",
    "             (6, 4), (7, 4), (8, 5), (9, 7), (10, 6),\n",
    "             (11, 4), (12, 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_RAW_DATA = \"s3://social-research-cheating/edges/raw_td.parquet\"\n",
    "\n",
    "for tup in file_nums:\n",
    "    pubg.combine_telemetry_data(tup[0], tup[1], PATH_TO_RAW_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read telemetry data stored in my S3 bucket.\n",
    "raw_td = spark.read.parquet(\"s3://social-research-cheating/edges/raw_td.parquet\")\n",
    "raw_td.registerTempTable(\"raw_td\")\n",
    "\n",
    "# Count the number of rows (= killings) in the dataframe.\n",
    "print(raw_td.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98319451\n"
     ]
    }
   ],
   "source": [
    "# Read telemetry data stored in my S3 bucket.\n",
    "raw_td = spark.read.parquet(\"s3://social-research-cheating/raw_td.parquet\")\n",
    "raw_td.registerTempTable(\"raw_td\")\n",
    "\n",
    "# Count the number of rows (= killings) in the dataframe.\n",
    "print(raw_td.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|                 mid|                 src|                 dst|                time|    m_date|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|01fd8f35-01ff-48f...|account.f1ef62d78...|account.bf5a2bdf5...|2019-03-03 14:19:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.e80a530e6...|account.8bd3cc440...|2019-03-03 14:19:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.e80a530e6...|account.52accebe5...|2019-03-03 14:19:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.6961c79f1...|account.e28657d14...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.caa44db60...|account.749a9649f...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.749a9649f...|account.6b9c75259...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.749a9649f...|account.02fe9c7cb...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.d7d801641...|account.caa44db60...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.6961c79f1...|account.a978bced1...|2019-03-03 14:20:...|2019-03-03|\n",
      "|01fd8f35-01ff-48f...|account.6961c79f1...|account.f1ef62d78...|2019-03-03 14:20:...|2019-03-03|\n",
      "+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the top 10 rows of the dataset.\n",
    "raw_td.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT mid)|\n",
      "+-------------------+\n",
      "|            1146941|\n",
      "+-------------------+\n",
      "\n",
      "+----------+-----------+\n",
      "|    m_date|num_of_mids|\n",
      "+----------+-----------+\n",
      "|2019-03-03|      45696|\n",
      "|2019-03-11|      29363|\n",
      "|2019-03-28|      24271|\n",
      "|2019-03-07|      31267|\n",
      "|2019-03-20|      29240|\n",
      "|2019-03-19|      29523|\n",
      "|2019-03-01|      48886|\n",
      "|2019-03-23|      50375|\n",
      "|2019-03-30|      49550|\n",
      "|2019-03-16|      50550|\n",
      "|2019-03-05|      30504|\n",
      "|2019-03-29|      36189|\n",
      "|2019-03-25|      29115|\n",
      "|2019-03-31|      45487|\n",
      "|2019-03-14|      29890|\n",
      "|2019-03-15|      37090|\n",
      "|2019-03-10|      46290|\n",
      "|2019-03-17|      45816|\n",
      "|2019-03-22|      36154|\n",
      "|2019-03-26|      27491|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of unique match IDs.\n",
    "unique_mids = spark.sql(\"SELECT COUNT(DISTINCT mid) FROM raw_td\")\n",
    "unique_mids.show()\n",
    "\n",
    "# Count the number of matches by date.\n",
    "mids_by_date = spark.sql(\"\"\"SELECT m_date, COUNT(DISTINCT mid) AS num_of_mids \n",
    "                            FROM raw_td GROUP BY m_date\"\"\")\n",
    "mids_by_date.show()\n",
    "\n",
    "# Store the table in the S3 bucket for the later use (plotting general statistics).\n",
    "mids_by_date.write.parquet(\"s3://social-research-cheating/general-stats/mids_by_date.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a dataset for cheater analysis.\n",
    "\n",
    "To compare cheaters and non-cheaters, we need to extract the records of matches played between March 1 and March 3.<br>\n",
    "The number of killings without self-loops between March 1 and March 3 is 12,216,898.\n",
    "\n",
    "The table below describes the variables in the data for cheater analysis:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid         | ID of the match               \n",
    "| src      | ID of the killer  \n",
    "| dst     | ID of the victim \n",
    "| time   | time in the format YYYY-MM-DD HH:MM:SS.SSS Z when the attack (killing) happened\n",
    "| m_date   | date in the format YYYY-MM-DD when the match was played "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12216898\n"
     ]
    }
   ],
   "source": [
    "raw_td = spark.read.parquet(\"s3://social-research-cheating/raw_td.parquet\")\n",
    "raw_td.registerTempTable(\"raw_td\")\n",
    "\n",
    "# Create a small dataset without self-loops.\n",
    "# The dataset below does not contain invalid edges (= edges with NULL).\n",
    "td = spark.sql(\"SELECT * FROM raw_td WHERE m_date <= '2019-03-03' AND src != dst\")\n",
    "print(td.count())\n",
    "\n",
    "# Store the data in the S3 bucket.\n",
    "td.write.parquet(\"s3://social-research-cheating/cheater-analysis/data_for_cheater_analysis.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a dataset that contains team membership information.\n",
    "\n",
    "The table below describes the variables in the team membership data:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid        | ID of the match               \n",
    "| id     | ID of the player  \n",
    "| tid     | ID of the team\n",
    "\n",
    "The number of teamplay matches is 1,022,520."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tables that contain the team membership information into one table.\n",
    "PATH_TO_TEAM_DATA = \"s3://social-research-cheating/team_data.parquet\"\n",
    "\n",
    "pubg.combine_team_data(31, 6, PATH_TO_TEAM_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---+\n",
      "|                 mid|                  id|tid|\n",
      "+--------------------+--------------------+---+\n",
      "|b6a091d4-2bdb-451...|account.9fbe4bbe5...|  1|\n",
      "|24d0a877-2d20-43a...|account.9ad264163...| 17|\n",
      "|866b5d75-0d8f-497...|account.4c10d9e9f...| 47|\n",
      "|476c22d8-d929-46c...|account.74c896572...| 21|\n",
      "|499aa106-272e-468...|account.bebee03c5...| 29|\n",
      "|355aafa1-b7a2-45c...|account.289b29eda...| 13|\n",
      "|4020041c-a4a6-46f...|account.4d93bc13f...| 35|\n",
      "|450b9c1c-6bd0-4d7...|account.a8a2ff4b7...| 15|\n",
      "|79ca6d6c-8f3a-485...|account.452fb2497...| 30|\n",
      "|02c36bd8-de13-479...|account.1a3ac664c...| 14|\n",
      "+--------------------+--------------------+---+\n",
      "only showing top 10 rows\n",
      "\n",
      "93730706\n"
     ]
    }
   ],
   "source": [
    "# Read the data stored in the S3 bucket.\n",
    "PATH_TO_TEAM_DATA = \"s3://social-research-cheating/team_data.parquet\"\n",
    "team_data = spark.read.parquet(PATH_TO_TEAM_DATA)\n",
    "\n",
    "# Show the top 10 rows of the dataset.\n",
    "team_data.show(10)\n",
    "\n",
    "# Count the number of rows in the dataframe.\n",
    "print(team_data.count())\n",
    "# The number of rows is 93,730,706."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data stored in the S3 bucket. \n",
    "team_data = spark.read.parquet(\"s3://social-research-cheating/team_data.parquet\")\n",
    "team_data.registerTempTable(\"team_data\")\n",
    "\n",
    "raw_td = spark.read.parquet(\"s3://social-research-cheating/raw_td.parquet\")\n",
    "raw_td.registerTempTable(\"raw_td\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique match IDs in the raw data.\n",
    "unique_mids = spark.sql(\"SELECT DISTINCT mid FROM raw_td\")\n",
    "unique_mids.registerTempTable(\"unique_mids\")\n",
    "unique_mids.write.parquet(\"s3://social-research-cheating/general-stats/unique_mids.parquet\")\n",
    "\n",
    "# Get unique match IDs in the team membership data.\n",
    "unique_team_mids = spark.sql(\"SELECT DISTINCT mid FROM team_data\")\n",
    "unique_team_mids.registerTempTable(\"unique_team_mids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of match IDs in both tables.\n",
    "team_mids = spark.sql(\"SELECT t.mid FROM unique_team_mids t JOIN unique_mids m ON t.mid = m.mid\")\n",
    "team_mids.write.parquet(\"s3://social-research-cheating/general-stats/unique_team_mids.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(DISTINCT mid)|\n",
      "+-------------------+\n",
      "|            1022520|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "team_mids = spark.read.parquet(\"s3://social-research-cheating/general-stats/unique_team_mids.parquet\")\n",
    "team_mids.registerTempTable(\"team_mids\")\n",
    "\n",
    "# Count the number of unique match IDs in the team membership data.\n",
    "team_mid_cnt = spark.sql(\"SELECT COUNT(DISTINCT mid) FROM team_mids\")\n",
    "team_mid_cnt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small team dataset.\n",
    "team_data = spark.read.parquet(\"s3://social-research-cheating/edges/small_team_data.parquet\")\n",
    "team_data.registerTempTable(\"team_data\")\n",
    "\n",
    "obs_data = spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\")\n",
    "obs_data.registerTempTable(\"obs_data\")\n",
    "\n",
    "# Get a list of unique match IDs from 'obs_data'.\n",
    "obs_mids = spark.sql(\"SELECT DISTINCT mid FROM obs_data\")\n",
    "obs_mids.registerTempTable(\"obs_mids\")\n",
    "\n",
    "# Count the number of match IDs in both tables.\n",
    "team_mids = spark.sql(\"SELECT t.mid, id, tid FROM team_data t JOIN obs_mids o ON t.mid = o.mid\")\n",
    "team_mids.write.parquet(\"s3://social-research-cheating/edges/tiny_team_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create a dataset for the use of analysing the observation-based mechanism.\n",
    "\n",
    "The dataset for analysing the observation-based mechanism should contain self-loops because players who killed themselves (self-loops) cannot observe what happens in the match after they die.<br>\n",
    "To reduce the amount of data, we extract the matches where at least one player was killed by cheating.<br>\n",
    "The number of unique match IDs in this dataset is 19,216.<br>\n",
    "\n",
    "The table below describes the variables in the data for analysing the observation-based mechanism:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid         | ID of the match               \n",
    "| src      | ID of the killer\n",
    "| src_sd      | date in the format YYYY-MM-DD when the killer started cheating ('NA' if the player is a non-cheater)\n",
    "| src_bd      | date in the format YYYY-MM-DD when the killer was banned ('NA' if the player is a non-cheater)\n",
    "| src_curr_flag      | 1 if the killer was cheating on the date when the match was played\n",
    "| src_flag      | 1 if the killer was banned, 0 otherwise\n",
    "| dst     | ID of the victim\n",
    "| dst_sd      | date in the format YYYY-MM-DD when the victim started cheating ('NA' if the player is a non-cheater)\n",
    "| dst_bd      | date in the format YYYY-MM-DD when the victim was banned ('NA' if the player is a non-cheater)\n",
    "| dst_curr_flag      | 1 if the victim was cheating on the date when the match was played\n",
    "| dst_flag      | 1 if the victim was banned, 0 otherwise\n",
    "| time   | time in the format YYYY-MM-DD HH:MM:SS.SSS Z when the attack (killing) happened\n",
    "| m_date   | date in the format YYYY-MM-DD when the match was played\n",
    "\n",
    "The number of edges is 1,693,699 and there are 7,522 self-loops in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_RAW_DATA = \"s3://social-research-cheating/raw_td.parquet\"\n",
    "players = spark.read.parquet(\"s3://social-research-cheating/nodes.parquet\")\n",
    "players.registerTempTable(\"players\")\n",
    "\n",
    "# Get the logs of the matches where at least one cheater took part in.\n",
    "pubg.get_obs_data(PATH_TO_RAW_DATA, players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1693699\n",
      "7522\n"
     ]
    }
   ],
   "source": [
    "obs_data = spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\")\n",
    "obs_data.registerTempTable(\"obs_data\")\n",
    "\n",
    "# Count the number of rows in the dataframe.\n",
    "print(obs_data.count())\n",
    "\n",
    "# Count the number of self-loops.\n",
    "self_loops = spark.sql(\"SELECT * FROM obs_data WHERE src = dst\")\n",
    "print(self_loops.count())\n",
    "\n",
    "# The number of edges is 1,693,699 and there are 7,522 self-loops in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create a dataset for the use of analysing the victimisation-based mechanism.\n",
    "\n",
    "We need the killing records of matches where cheaters killed at least one player without self-loops.<br> \n",
    "We can simply reuse the dataset for the observation-based mechanism by getting rid of self-loops from it.<br>\n",
    "Thus, the number of edges should be 1,693,699 - 7,522 = 1,686,177.\n",
    "\n",
    "The table below describes the variables in the data for analysing the victimisation-based mechanism:\n",
    "\n",
    "| Variable   | Explanation   \n",
    "|:-----------|:-------\n",
    "| mid         | ID of the match               \n",
    "| src      | ID of the killer\n",
    "| src_sd      | date in the format YYYY-MM-DD when the killer started cheating ('NA' if the player is a non-cheater)\n",
    "| src_bd      | date in the format YYYY-MM-DD when the killer was banned ('NA' if the player is a non-cheater)\n",
    "| src_curr_flag      | 1 if the killer was cheating on the date when the match was played\n",
    "| src_flag      | 1 if the killer was banned, 0 otherwise\n",
    "| dst     | ID of the victim\n",
    "| dst_sd      | date in the format YYYY-MM-DD when the victim started cheating ('NA' if the player is a non-cheater)\n",
    "| dst_bd      | date in the format YYYY-MM-DD when the victim was banned ('NA' if the player is a non-cheater)\n",
    "| dst_flag      | 1 if the victim was banned, 0 otherwise\n",
    "| dst_curr_flag      | 1 if the victim was cheating on the date when the match was played\n",
    "| time   | time in the format YYYY-MM-DD HH:MM:SS.SSS Z when the attack (killing) happened\n",
    "| m_date   | date in the format YYYY-MM-DD when the match was played\n",
    "\n",
    "The number of edges in this dataset is 1,686,177."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for analysing the victimisation-based mechanism.\n",
    "spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\").createOrReplaceTempView(\"raw_data\")\n",
    "cleaned_data = spark.sql(\"SELECT * FROM raw_data WHERE src != dst\") # Remove self-loops.\n",
    "cleaned_data.write.parquet(\"s3://social-research-cheating/edges/vic_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1686177\n"
     ]
    }
   ],
   "source": [
    "vic_data = spark.read.parquet(\"s3://social-research-cheating/edges/vic_data.parquet\")\n",
    "print(vic_data.count())\n",
    "\n",
    "# The number of edges should be 1,693,699 - 7,522 = 1,686,177."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the number of winners and test whether winners have the same team ID for each match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a table that contains killings.\n",
    "obs_data = spark.read.parquet(\"s3://social-research-cheating/edges/obs_data.parquet\")\n",
    "obs_data.registerTempTable(\"obs_data\")\n",
    "\n",
    "# Read a table that contains team membership data.\n",
    "team_info = spark.read.parquet(\"s3://social-research-cheating/edges/tiny_team_data.parquet\")\n",
    "team_info.registerTempTable(\"team_ids\")\n",
    "\n",
    "players = spark.read.parquet(\"s3://social-research-cheating/nodes.parquet\")\n",
    "players.registerTempTable(\"players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of mids and m_dates.\n",
    "match_info = spark.sql(\"SELECT DISTINCT mid, m_date FROM obs_data\")\n",
    "match_info.registerTempTable(\"match_info\")\n",
    "\n",
    "# Get a list of victims for each match.\n",
    "victims = spark.sql(\"SELECT DISTINCT mid, dst FROM obs_data\")\n",
    "victims.registerTempTable(\"victims\")\n",
    "\n",
    "# Get a list of winners for each match.\n",
    "winners = spark.sql(\"\"\"SELECT DISTINCT o.mid, src FROM obs_data o \n",
    "                       WHERE NOT EXISTS (SELECT mid, dst FROM victims v WHERE o.mid = v.mid AND o.src = v.dst)\"\"\")\n",
    "winners.registerTempTable(\"winners\")\n",
    "\n",
    "# Add team information.\n",
    "add_tids = spark.sql(\"\"\"SELECT w.mid, src, CASE WHEN tid IS NULL THEN 'NA' ELSE tid END AS src_tid\n",
    "                        FROM winners w LEFT JOIN team_ids t ON w.mid = t.mid AND w.src = t.id\"\"\")\n",
    "add_tids.registerTempTable(\"add_tids\")\n",
    "\n",
    "# Add m_dates.\n",
    "temp_tab = spark.sql(\"\"\"SELECT a.mid, src, src_tid, m_date \n",
    "                        FROM add_tids a LEFT JOIN match_info m ON a.mid = m.mid\"\"\")\n",
    "temp_tab.registerTempTable(\"temp_tab\")\n",
    "\n",
    "# Find the matches where at least one winner's team ID is 'NA'.\n",
    "na_tids = spark.sql(\"SELECT DISTINCT mid FROM add_tids WHERE src_tid = 'NA'\")\n",
    "na_tids.registerTempTable(\"na_tids\")\n",
    "\n",
    "# Add the current cheating flag of players.\n",
    "winners = spark.sql(\"\"\"SELECT t.*, \n",
    "                       CASE WHEN cheating_flag = 1 AND m_date < start_date THEN 1 ELSE 0 END AS pot_flag \n",
    "                       FROM temp_tab t LEFT JOIN players p ON t.src = p.id\"\"\")\n",
    "winners.registerTempTable(\"winners\")\n",
    "\n",
    "# Count the number of winners and that of unique times for each match. \n",
    "cnt_tab = spark.sql(\"\"\"SELECT mid, COUNT(src) AS winner_cnt, \n",
    "                       COUNT(DISTINCT src_tid) AS tid_cnt, SUM(pot_flag) AS pot_cnt \n",
    "                       FROM winners GROUP BY mid\"\"\")\n",
    "cnt_tab.registerTempTable(\"cnt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+-------+-------+\n",
      "|                 mid|winner_cnt|tid_cnt|pot_cnt|na_flag|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "|0143e2da-14d2-4d8...|         9|      6|      0|      0|\n",
      "|036a8903-186b-45f...|         4|      2|      0|      0|\n",
      "|080d5622-6b94-4d7...|         3|      2|      0|      0|\n",
      "|0c7d472e-5064-4d4...|         2|      2|      0|      0|\n",
      "|0ef25288-88d3-476...|         2|      1|      0|      0|\n",
      "|1203abce-50ec-40d...|         4|      4|      0|      0|\n",
      "|1574a6bb-a63f-473...|         5|      2|      0|      0|\n",
      "|16d6f605-4118-4de...|         4|      3|      0|      0|\n",
      "|1773f8d7-b807-439...|         3|      2|      0|      0|\n",
      "|194e1d81-b65c-4dc...|         4|      2|      0|      0|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_tab = spark.sql(\"\"\"SELECT c.mid, winner_cnt, tid_cnt, pot_cnt, \n",
    "                           CASE WHEN n.mid IS NULL THEN 0 ELSE 1 END AS na_flag \n",
    "                           FROM cnt_tab c LEFT JOIN na_tids n ON c.mid = n.mid\"\"\")\n",
    "summary_tab.registerTempTable(\"summary_tab\")\n",
    "summary_tab.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+-------+-------+\n",
      "|                 mid|winner_cnt|tid_cnt|pot_cnt|na_flag|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "|013caebc-8504-4d7...|         4|      4|      1|      0|\n",
      "|0bd6149a-c6f5-4ed...|         9|      7|      1|      0|\n",
      "|0c2c1334-9af0-41d...|        11|      6|      1|      0|\n",
      "|2dc03f99-5d44-42e...|         7|      5|      1|      0|\n",
      "|35866cf5-93de-48a...|         4|      2|      1|      0|\n",
      "|391b03c1-3393-4af...|         9|      5|      1|      0|\n",
      "|3bbd09e0-d4af-4ac...|         5|      3|      1|      0|\n",
      "|456bc019-80ee-4c6...|         4|      3|      1|      0|\n",
      "|86ef180f-da6b-4b2...|         5|      3|      1|      0|\n",
      "|9c7144ce-008e-41d...|         5|      3|      1|      0|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "1964\n"
     ]
    }
   ],
   "source": [
    "# summary_tab.write.parquet(\"s3://social-research-cheating/general-stats/sum_tab_of_winners.parquet\")\n",
    "summary_tab = spark.read.parquet(\"s3://social-research-cheating/general-stats/sum_tab_of_winners.parquet\")\n",
    "summary_tab.registerTempTable(\"summary_tab\")\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM summary_tab WHERE tid_cnt > 1 AND pot_cnt >= 1\")\n",
    "temp.show(10)\n",
    "print(temp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------+-------+-------+\n",
      "|                 mid|winner_cnt|tid_cnt|pot_cnt|na_flag|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "|9d8edf15-f814-48f...|         5|      2|      1|      1|\n",
      "|b2c7e5a4-f0f0-48d...|         5|      3|      1|      1|\n",
      "|dfae8103-19b6-4c1...|         7|      6|      1|      1|\n",
      "|b62ae865-af8e-4e3...|         3|      2|      2|      1|\n",
      "|2da2cc0d-41d1-487...|         9|      5|      1|      1|\n",
      "|12bcdfe5-34a4-473...|         4|      3|      1|      1|\n",
      "|13c1ad12-8e12-4a1...|         9|      6|      1|      1|\n",
      "|bb78c330-ea48-42a...|         4|      2|      1|      1|\n",
      "|7b6c2381-afde-452...|        13|      9|      1|      1|\n",
      "|f2f76e66-9fb7-40d...|         8|      6|      1|      1|\n",
      "+--------------------+----------+-------+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "summary_tab = spark.read.parquet(\"s3://social-research-cheating/general-stats/sum_tab_of_winners.parquet\")\n",
    "summary_tab.registerTempTable(\"summary_tab\")\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM summary_tab WHERE tid_cnt > 1 AND pot_cnt >= 1 AND na_flag = 1\")\n",
    "temp.show(10)\n",
    "print(temp.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19216\n"
     ]
    }
   ],
   "source": [
    "uniq_mids = spark.sql(\"SELECT DISTINCT mid FROM obs_data\")\n",
    "print(uniq_mids.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temp = spark.sql(\"SELECT * FROM summary_tab WHERE tid_cnt > 1 AND pot_cnt >= 1 AND na_flag = 1\")\n",
    "temp_df = temp.toPandas()\n",
    "temp_df.to_csv('na_flags.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
