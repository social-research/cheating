{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06-combine-two-mechanisms.ipynb\n",
    "======================\n",
    "\n",
    "In this section, we use the two tables from the previous sections to combine the two different mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and read tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, when\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a summary table of the victimisation-based mechanism.\n",
    "vic_tab = spark.read.parquet(\"s3://jinny-capstone-data-test/summary-tables/emp-net/vic_tab.parquet\")\n",
    "vic_tab.registerTempTable(\"vic_tab\")\n",
    "\n",
    "# Read a summary table of the observation-based mechanism.\n",
    "obs_tab = spark.read.parquet(\"s3://jinny-capstone-data-test/summary-tables/emp-net/obs_tab.parquet\")\n",
    "obs_tab.registerTempTable(\"obs_tab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Merge two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_tab = vic_tab.join(obs_tab, on=['id', 'start_date'], how='outer')\n",
    "merged_tab.show(20)\n",
    "# merged_tab.fillna(0, subset=['a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the number of times the motif appears in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the number of cheaters who adopted cheating after being killed by cheating once and observing two cheaters.\n",
    "merged_tab.registerTempTable(\"merged_tab\")\n",
    "\n",
    "motifs = spark.sql(\"SELECT * FROM merged_tab WHERE total_exp = 1 AND uniq_cheaters = 2\")\n",
    "motifs.show()\n",
    "print(motifs.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the distribution of experiences and observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins = np.arange(0, complete_rows['period'].max() + 1.5) - 0.5\n",
    "fig = merged_tab.scatter(merged_tab['total_exp'], merged_tab['total_obs'])\n",
    "plt.title('')\n",
    "# plt.xlim(xmin = 0)\n",
    "# plt.xlim(xmax = 1)\n",
    "plt.xlabel('Number of total victimisation experiences')\n",
    "plt.ylabel('Number of total observations')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
